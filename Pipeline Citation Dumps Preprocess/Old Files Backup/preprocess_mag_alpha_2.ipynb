{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************************\n",
    "# Preprocess Microsoft Academics Graph (MAG) Dataset\n",
    "# ***************************************************************\n",
    "\n",
    "# Jupyter Notebook for the preprocessing of the Microsoft Academics Graph (MAG) dump\n",
    "#\n",
    "# TODO **********\n",
    "# In particular, the following operations are going to be executed:\n",
    "# - Opening of ConferenceInstances and ConferenceSeries CSVs\n",
    "# - Drop of the useless columns \n",
    "# - Merge of the two CSVs on the ConferenceSeriesID column\n",
    "# - Chuncked Processing of the Papers CSV\n",
    "# ---- Drop of the useless columns\n",
    "# ---- Drop of papers from journals and books rows\n",
    "# - Merge with the processed conferences data\n",
    "#\n",
    "# Lastly, the entire preprocessed dump is going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/MAG/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/MAG_Chunks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* CONFERENCE INSTANCES ********************\n",
    "\n",
    "# Read of the Conference Instances File\n",
    "\n",
    "# The column names follow the MAG' scheme official documentation\n",
    "df_mag_conf_instances_col_names = ['ConferenceInstanceID', 'NormalizedName', 'DisplayName', 'ConferenceSeriesID', 'Location', 'OfficialUrl', 'StartDate', 'EndDate', 'AbstractRegistrationDate', 'SubmissionDeadlineDate', 'NotificationDueDate', 'FinalVersionDueDate', 'PageCount', 'PaperFamilyCount', 'CitationCount', 'Latitude', 'Longitude', 'CreatedDate']\n",
    "\n",
    "df_mag_conf_instances = pd.read_csv(path_file_import + 'ConferenceInstances.txt', sep='\\t', names=df_mag_conf_instances_col_names)\n",
    "df_mag_conf_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop of Conference Instances' Useless Columns\n",
    "df_mag_conf_instances = df_mag_conf_instances.drop(columns=['OfficialUrl', 'AbstractRegistrationDate', 'SubmissionDeadlineDate', 'NotificationDueDate', 'FinalVersionDueDate', 'PageCount', 'PaperFamilyCount', 'CitationCount', 'Latitude', 'Longitude', 'CreatedDate', 'StartDate', 'EndDate'])\n",
    "df_mag_conf_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column rename to remove ambiguity for the future joins\n",
    "df_mag_conf_instances.rename(columns={'NormalizedName': 'ConferenceNormalizedName', 'DisplayName': 'ConferenceDisplayName', 'Location': 'ConferenceLocation'}, inplace=True)\n",
    "df_mag_conf_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* CONFERENCE SERIES ********************\n",
    "\n",
    "# Read of the Conference Series File\n",
    "\n",
    "# The column names follow the MAG' scheme official documentation\n",
    "df_mag_conf_series_col_names = ['ConferenceSeriesID', 'Rank', 'NormalizedName', 'DisplayName', 'PaperCount', 'PaperFamilyCount', 'CitationCount', 'CreatedDate']\n",
    "\n",
    "df_mag_conf_series = pd.read_csv(path_file_import + 'ConferenceSeries.txt', sep='\\t', names=df_mag_conf_series_col_names)\n",
    "df_mag_conf_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop of Conference Series' Useless Columns\n",
    "df_mag_conf_series = df_mag_conf_series.drop(columns=['Rank', 'PaperCount', 'PaperFamilyCount', 'CitationCount', 'CreatedDate'])\n",
    "df_mag_conf_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column rename to remove ambiguity for the future joins\n",
    "df_mag_conf_series.rename(columns={'NormalizedName': 'ConferenceSeriesNormalizedName', 'DisplayName': 'ConferenceSeriesDisplayName'}, inplace=True)\n",
    "df_mag_conf_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* MERGE OF CONFERENCE DATA ********************\n",
    "\n",
    "# Merge of the conference series and conference instances dataframes over the conferenceseriesid column\n",
    "df_mag_conf_merged = df_mag_conf_instances.merge(df_mag_conf_series, on='ConferenceSeriesID')\n",
    "df_mag_conf_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed chunk 1 out of around 20.0\n",
      "Successfully processed chunk 2 out of around 20.0\n",
      "Successfully processed chunk 3 out of around 20.0\n",
      "Successfully processed chunk 4 out of around 20.0\n",
      "Successfully processed chunk 5 out of around 20.0\n",
      "Successfully processed chunk 6 out of around 20.0\n",
      "Successfully processed chunk 7 out of around 20.0\n",
      "Successfully processed chunk 8 out of around 20.0\n",
      "Successfully processed chunk 9 out of around 20.0\n",
      "Successfully processed chunk 10 out of around 20.0\n",
      "Successfully processed chunk 11 out of around 20.0\n",
      "Successfully processed chunk 12 out of around 20.0\n",
      "Successfully processed chunk 13 out of around 20.0\n",
      "Successfully processed chunk 14 out of around 20.0\n",
      "Successfully processed chunk 15 out of around 20.0\n",
      "Successfully processed chunk 16 out of around 20.0\n",
      "Successfully processed chunk 17 out of around 20.0\n",
      "Successfully processed chunk 18 out of around 20.0\n",
      "Successfully processed chunk 19 out of around 20.0\n",
      "Successfully processed chunk 20 out of around 20.0\n",
      "Successfully processed chunk 21 out of around 20.0\n",
      "Successfully processed chunk 22 out of around 20.0\n",
      "Successfully processed chunk 23 out of around 20.0\n",
      "Successfully processed chunk 24 out of around 20.0\n",
      "Successfully processed chunk 25 out of around 20.0\n",
      "Successfully processed chunk 26 out of around 20.0\n"
     ]
    }
   ],
   "source": [
    "# ******************* PAPERS ********************\n",
    "\n",
    "# The Papers CSV is going to be processed in chunks, due to its size\n",
    "\n",
    "# The column names follow the MAG' scheme official documentation\n",
    "df_mag_papers_col_names = ['PaperID', 'Rank', 'Doi', 'DocType', 'PaperTitle', 'OriginalTitle', 'BookTitle', 'Year', 'Date', 'OnlineDate', 'Publisher', 'JournalID', 'ConferenceSeriesID', 'ConferenceInstanceID', 'Volume', 'Issue', 'FirstPage', 'LastPage', 'ReferenceCount', 'CitationCount', 'EstimatedCitation', 'OriginalVenue', 'FamilyID', 'FamilyRank', 'Retracion', 'CreatedDate']\n",
    "\n",
    "# List of processed chunks.\n",
    "df_mag_papers_list_of_chunks = list()\n",
    "\n",
    "# Define of the chunk size\n",
    "chunksize = 10 ** 7\n",
    "\n",
    "count = 1\n",
    "with pd.read_csv(path_file_import + 'Papers.txt', sep='\\t', chunksize=chunksize, low_memory=False, on_bad_lines='skip', names=df_mag_papers_col_names) as reader:\n",
    "    for chunk in reader:\n",
    "\n",
    "        # Drop of the useless columns\n",
    "        chunk = chunk.drop(columns=['Rank', 'OnlineDate', 'Publisher', 'Volume', 'Issue', 'FirstPage', 'LastPage', 'ReferenceCount', 'OriginalVenue', 'FamilyID', 'FamilyRank', 'Retracion', 'CreatedDate', 'JournalID', 'BookTitle', 'Date'])\n",
    "\n",
    "        # Filtering of papers without DOI\n",
    "        chunk = chunk.dropna(subset = ['Doi'])\n",
    "\n",
    "        # Filtering papers that are not related to conferences\n",
    "        chunk = chunk[chunk.DocType == 'Conference']\n",
    "\n",
    "        # Drop of the doctype column\n",
    "        chunk = chunk.drop(columns=['DocType'])\n",
    "\n",
    "        # Insert of the resulting chunk in the list \n",
    "        df_mag_papers_list_of_chunks.append(chunk)\n",
    "\n",
    "        print(f'Successfully processed chunk {count} out of around {200000000 / chunksize}')\n",
    "        count += 1\n",
    "\n",
    "# Concatenation of the processed chunks\n",
    "df_mag_papers = pd.concat(df_mag_papers_list_of_chunks)\n",
    "\n",
    "# Empty the list to free some memory\n",
    "df_mag_papers_list_of_chunks = list()\n",
    "\n",
    "# Write of the resulting CSV on Disk\n",
    "df_mag_papers.to_csv(path_file_export + 'out_mag_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Doi</th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "      <th>ConferenceSeriesID</th>\n",
       "      <th>ConferenceInstanceID</th>\n",
       "      <th>CitationCount</th>\n",
       "      <th>EstimatedCitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14558443</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>the adaptive priority queue with elimination a...</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.131603e+09</td>\n",
       "      <td>4038532.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15354235</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>document retrieval on repetitive collections</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.154039e+09</td>\n",
       "      <td>157008481.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>24327294</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>socomo marketing for travel and tourism</td>\n",
       "      <td>SoCoMo Marketing for Travel and Tourism</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.196984e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>60437532</td>\n",
       "      <td>10.1007/3-540-46146-9_77</td>\n",
       "      <td>similarity image retrieval system using hierar...</td>\n",
       "      <td>Similarity Image Retrieval System Using Hierar...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.192665e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>198056957</td>\n",
       "      <td>10.1007/11785231_94</td>\n",
       "      <td>leukemia prediction from gene expression data ...</td>\n",
       "      <td>Leukemia prediction from gene expression data—...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1.176896e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259718386</th>\n",
       "      <td>3102242761</td>\n",
       "      <td>10.1109/IECON43393.2020.9254316</td>\n",
       "      <td>loss reduction by synchronous rectification in...</td>\n",
       "      <td>Loss Reduction by Synchronous Rectification in...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.623572e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259718500</th>\n",
       "      <td>3136855299</td>\n",
       "      <td>10.1109/BMSB49480.2020.9379806</td>\n",
       "      <td>data over cable services improving the bicm ca...</td>\n",
       "      <td>Data Over Cable Services – Improving the BICM ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.623662e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259718537</th>\n",
       "      <td>3145351916</td>\n",
       "      <td>10.1109/ACC.1988.4172843</td>\n",
       "      <td>model reference robust adaptive control withou...</td>\n",
       "      <td>Model Reference Robust Adaptive Control withou...</td>\n",
       "      <td>1988</td>\n",
       "      <td>2.238538e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259718570</th>\n",
       "      <td>3151696876</td>\n",
       "      <td>10.1109/ICASSP.2002.1005676</td>\n",
       "      <td>missing data speech recognition in reverberant...</td>\n",
       "      <td>Missing data speech recognition in reverberant...</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.121228e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259718611</th>\n",
       "      <td>3162646375</td>\n",
       "      <td>10.1109/ITCA52113.2020.00077</td>\n",
       "      <td>research on text to image based on generative ...</td>\n",
       "      <td>Research on Text to Image Based on Generative ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.622834e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4409816 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PaperID                              Doi  \\\n",
       "37           14558443     10.1007/978-3-662-45174-8_28   \n",
       "39           15354235     10.1007/978-3-662-44777-2_60   \n",
       "68           24327294     10.1007/978-3-319-03973-2_13   \n",
       "197          60437532         10.1007/3-540-46146-9_77   \n",
       "666         198056957              10.1007/11785231_94   \n",
       "...               ...                              ...   \n",
       "259718386  3102242761  10.1109/IECON43393.2020.9254316   \n",
       "259718500  3136855299   10.1109/BMSB49480.2020.9379806   \n",
       "259718537  3145351916         10.1109/ACC.1988.4172843   \n",
       "259718570  3151696876      10.1109/ICASSP.2002.1005676   \n",
       "259718611  3162646375     10.1109/ITCA52113.2020.00077   \n",
       "\n",
       "                                                  PaperTitle  \\\n",
       "37         the adaptive priority queue with elimination a...   \n",
       "39              document retrieval on repetitive collections   \n",
       "68                   socomo marketing for travel and tourism   \n",
       "197        similarity image retrieval system using hierar...   \n",
       "666        leukemia prediction from gene expression data ...   \n",
       "...                                                      ...   \n",
       "259718386  loss reduction by synchronous rectification in...   \n",
       "259718500  data over cable services improving the bicm ca...   \n",
       "259718537  model reference robust adaptive control withou...   \n",
       "259718570  missing data speech recognition in reverberant...   \n",
       "259718611  research on text to image based on generative ...   \n",
       "\n",
       "                                               OriginalTitle  Year  \\\n",
       "37         The Adaptive Priority Queue with Elimination a...  2014   \n",
       "39              Document Retrieval on Repetitive Collections  2014   \n",
       "68                   SoCoMo Marketing for Travel and Tourism  2013   \n",
       "197        Similarity Image Retrieval System Using Hierar...  2002   \n",
       "666        Leukemia prediction from gene expression data—...  2006   \n",
       "...                                                      ...   ...   \n",
       "259718386  Loss Reduction by Synchronous Rectification in...  2020   \n",
       "259718500  Data Over Cable Services – Improving the BICM ...  2020   \n",
       "259718537  Model Reference Robust Adaptive Control withou...  1988   \n",
       "259718570  Missing data speech recognition in reverberant...  2002   \n",
       "259718611  Research on Text to Image Based on Generative ...  2020   \n",
       "\n",
       "           ConferenceSeriesID  ConferenceInstanceID  CitationCount  \\\n",
       "37               1.131603e+09             4038532.0           12.0   \n",
       "39               1.154039e+09           157008481.0           10.0   \n",
       "68               1.196984e+09                   NaN           20.0   \n",
       "197              1.192665e+09                   NaN            0.0   \n",
       "666              1.176896e+09                   NaN           19.0   \n",
       "...                       ...                   ...            ...   \n",
       "259718386        2.623572e+09                   NaN            0.0   \n",
       "259718500        2.623662e+09                   NaN            0.0   \n",
       "259718537        2.238538e+09                   NaN            0.0   \n",
       "259718570        1.121228e+09                   NaN            0.0   \n",
       "259718611        2.622834e+09                   NaN            0.0   \n",
       "\n",
       "          EstimatedCitation  \n",
       "37                       12  \n",
       "39                       10  \n",
       "68                       20  \n",
       "197                       0  \n",
       "666                      19  \n",
       "...                     ...  \n",
       "259718386                 0  \n",
       "259718500                 0  \n",
       "259718537                 0  \n",
       "259718570                 0  \n",
       "259718611                 0  \n",
       "\n",
       "[4409816 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mag_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Doi</th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>ConferenceSeriesID</th>\n",
       "      <th>ConferenceInstanceID</th>\n",
       "      <th>CitationCount</th>\n",
       "      <th>EstimatedCitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40000031</th>\n",
       "      <td>2214036112</td>\n",
       "      <td>10.1049/CP.2014.0661</td>\n",
       "      <td>robustness results of lqr based systems with s...</td>\n",
       "      <td>Robustness results of LQR-based systems with s...</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>2.754225e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000039</th>\n",
       "      <td>2222504151</td>\n",
       "      <td>10.24297/IJCT.V2I2A.6738</td>\n",
       "      <td>advanced it outsourcing by using cloud computi...</td>\n",
       "      <td>Advanced IT Outsourcing By Using Cloud Computi...</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>1.199066e+09</td>\n",
       "      <td>149248753.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000084</th>\n",
       "      <td>2248247860</td>\n",
       "      <td>10.1109/SSCI.2015.254</td>\n",
       "      <td>computational intelligence for efficient numer...</td>\n",
       "      <td>Computational Intelligence for Efficient Numer...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>2.756343e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000164</th>\n",
       "      <td>2283297016</td>\n",
       "      <td>10.2312/EGVE.20151316</td>\n",
       "      <td>bimanual haptic simulation of bone fracturing ...</td>\n",
       "      <td>Bimanual haptic simulation of bone fracturing ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>2.754337e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40000430</th>\n",
       "      <td>2395305208</td>\n",
       "      <td>10.1007/978-3-319-29613-5_12</td>\n",
       "      <td>auspice automatic safety property verification...</td>\n",
       "      <td>AUSPICE: Automatic Safety Property Verificatio...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-07-18</td>\n",
       "      <td>1.160078e+09</td>\n",
       "      <td>582805039.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999714</th>\n",
       "      <td>2159517361</td>\n",
       "      <td>10.1109/IROS.1995.525788</td>\n",
       "      <td>a navigation system based upon panoramic repre...</td>\n",
       "      <td>A navigation system based upon panoramic repre...</td>\n",
       "      <td>1995</td>\n",
       "      <td>1995-08-05</td>\n",
       "      <td>1.143279e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999715</th>\n",
       "      <td>2160008470</td>\n",
       "      <td>10.1109/GLOCOM.2003.1258668</td>\n",
       "      <td>estimating statistical properties of composite...</td>\n",
       "      <td>Estimating statistical properties of composite...</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>1.131421e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999717</th>\n",
       "      <td>2160885247</td>\n",
       "      <td>10.1109/MILCOM.2008.4753062</td>\n",
       "      <td>waveform and rf power amplifier interdependenc...</td>\n",
       "      <td>Waveform and RF power amplifier interdependenc...</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008-11-01</td>\n",
       "      <td>2.624606e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999725</th>\n",
       "      <td>2164639906</td>\n",
       "      <td>10.1109/ACC.2007.4282873</td>\n",
       "      <td>model predictive control based on mixed h2 h c...</td>\n",
       "      <td>Model Predictive Control based on Mixed H2/H C...</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007-07-09</td>\n",
       "      <td>2.238538e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999743</th>\n",
       "      <td>2174019521</td>\n",
       "      <td>10.1109/HPCC-CSS-ICESS.2015.33</td>\n",
       "      <td>realistic task parallelization of the h 264 de...</td>\n",
       "      <td>Realistic Task Parallelization of the H.264 De...</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-08-24</td>\n",
       "      <td>1.148948e+09</td>\n",
       "      <td>63471800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169641 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PaperID                             Doi  \\\n",
       "40000031  2214036112            10.1049/CP.2014.0661   \n",
       "40000039  2222504151        10.24297/IJCT.V2I2A.6738   \n",
       "40000084  2248247860           10.1109/SSCI.2015.254   \n",
       "40000164  2283297016           10.2312/EGVE.20151316   \n",
       "40000430  2395305208    10.1007/978-3-319-29613-5_12   \n",
       "...              ...                             ...   \n",
       "49999714  2159517361        10.1109/IROS.1995.525788   \n",
       "49999715  2160008470     10.1109/GLOCOM.2003.1258668   \n",
       "49999717  2160885247     10.1109/MILCOM.2008.4753062   \n",
       "49999725  2164639906        10.1109/ACC.2007.4282873   \n",
       "49999743  2174019521  10.1109/HPCC-CSS-ICESS.2015.33   \n",
       "\n",
       "                                                 PaperTitle  \\\n",
       "40000031  robustness results of lqr based systems with s...   \n",
       "40000039  advanced it outsourcing by using cloud computi...   \n",
       "40000084  computational intelligence for efficient numer...   \n",
       "40000164  bimanual haptic simulation of bone fracturing ...   \n",
       "40000430  auspice automatic safety property verification...   \n",
       "...                                                     ...   \n",
       "49999714  a navigation system based upon panoramic repre...   \n",
       "49999715  estimating statistical properties of composite...   \n",
       "49999717  waveform and rf power amplifier interdependenc...   \n",
       "49999725  model predictive control based on mixed h2 h c...   \n",
       "49999743  realistic task parallelization of the h 264 de...   \n",
       "\n",
       "                                              OriginalTitle  Year        Date  \\\n",
       "40000031  Robustness results of LQR-based systems with s...  2014  2014-09-29   \n",
       "40000039  Advanced IT Outsourcing By Using Cloud Computi...  2012  2012-04-30   \n",
       "40000084  Computational Intelligence for Efficient Numer...  2015  2015-12-01   \n",
       "40000164  Bimanual haptic simulation of bone fracturing ...  2015  2015-10-28   \n",
       "40000430  AUSPICE: Automatic Safety Property Verificatio...  2015  2015-07-18   \n",
       "...                                                     ...   ...         ...   \n",
       "49999714  A navigation system based upon panoramic repre...  1995  1995-08-05   \n",
       "49999715  Estimating statistical properties of composite...  2003  2003-12-01   \n",
       "49999717  Waveform and RF power amplifier interdependenc...  2008  2008-11-01   \n",
       "49999725  Model Predictive Control based on Mixed H2/H C...  2007  2007-07-09   \n",
       "49999743  Realistic Task Parallelization of the H.264 De...  2015  2015-08-24   \n",
       "\n",
       "          ConferenceSeriesID  ConferenceInstanceID  CitationCount  \\\n",
       "40000031        2.754225e+09                   NaN            3.0   \n",
       "40000039        1.199066e+09           149248753.0            2.0   \n",
       "40000084        2.756343e+09                   NaN            1.0   \n",
       "40000164        2.754337e+09                   NaN            0.0   \n",
       "40000430        1.160078e+09           582805039.0            9.0   \n",
       "...                      ...                   ...            ...   \n",
       "49999714        1.143279e+09                   NaN            3.0   \n",
       "49999715        1.131421e+09                   NaN            8.0   \n",
       "49999717        2.624606e+09                   NaN            2.0   \n",
       "49999725        2.238538e+09                   NaN           37.0   \n",
       "49999743        1.148948e+09            63471800.0            2.0   \n",
       "\n",
       "         EstimatedCitation  \n",
       "40000031                 3  \n",
       "40000039                 2  \n",
       "40000084                 1  \n",
       "40000164                 0  \n",
       "40000430                 9  \n",
       "...                    ...  \n",
       "49999714                 3  \n",
       "49999715                 8  \n",
       "49999717                 2  \n",
       "49999725                66  \n",
       "49999743                 2  \n",
       "\n",
       "[169641 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>Doi</th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "      <th>ConferenceSeriesID</th>\n",
       "      <th>ConferenceInstanceID</th>\n",
       "      <th>CitationCount</th>\n",
       "      <th>EstimatedCitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14558443</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>the adaptive priority queue with elimination a...</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.131603e+09</td>\n",
       "      <td>4.038532e+06</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15354235</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>document retrieval on repetitive collections</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.154039e+09</td>\n",
       "      <td>1.570085e+08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1459710595</td>\n",
       "      <td>10.1007/978-3-319-08958-4_17</td>\n",
       "      <td>enhancing labeled data using unlabeled data fo...</td>\n",
       "      <td>Enhancing Labeled Data Using Unlabeled Data fo...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.760407e+09</td>\n",
       "      <td>2.019264e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2161259116</td>\n",
       "      <td>10.1109/CVPR.2013.65</td>\n",
       "      <td>improved image set classification via joint sp...</td>\n",
       "      <td>Improved Image Set Classification via Joint Sp...</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.158168e+09</td>\n",
       "      <td>1.383691e+08</td>\n",
       "      <td>75.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>1488332647</td>\n",
       "      <td>10.1109/ISBMSB.2008.4536671</td>\n",
       "      <td>a novel channel estimation based on spread pil...</td>\n",
       "      <td>A novel channel estimation based on spread pil...</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.623662e+09</td>\n",
       "      <td>2.626942e+09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259717113</th>\n",
       "      <td>2789624042</td>\n",
       "      <td>10.1109/ISSCC.2018.8310368</td>\n",
       "      <td>a 95 2 efficiency dual path dc dc step up conv...</td>\n",
       "      <td>A 95.2% efficiency dual-path DC-DC step-up con...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.183230e+09</td>\n",
       "      <td>2.788559e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259717694</th>\n",
       "      <td>2893506456</td>\n",
       "      <td>10.1007/978-3-030-01418-6_54</td>\n",
       "      <td>learning preferences for large scale multi lab...</td>\n",
       "      <td>Learning Preferences for Large Scale Multi-lab...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.158833e+09</td>\n",
       "      <td>2.892231e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259717766</th>\n",
       "      <td>2914533952</td>\n",
       "      <td>10.1145/3308558.3313726</td>\n",
       "      <td>city wide signal strength maps prediction with...</td>\n",
       "      <td>City-Wide Signal Strength Maps: Prediction wit...</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.135342e+09</td>\n",
       "      <td>2.890478e+09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259717787</th>\n",
       "      <td>2921629601</td>\n",
       "      <td>10.1109/ICOSC.2019.8665672</td>\n",
       "      <td>constructing and maintaining corpus driven ann...</td>\n",
       "      <td>Constructing and Maintaining Corpus-Driven Ann...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.898614e+09</td>\n",
       "      <td>2.889800e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259717991</th>\n",
       "      <td>2967304537</td>\n",
       "      <td>10.1109/ICRA.2019.8794157</td>\n",
       "      <td>1 actuator 3 dof manipulation using an underac...</td>\n",
       "      <td>1-Actuator 3-DoF Manipulation Using an Underac...</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.163902e+09</td>\n",
       "      <td>2.891770e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1431517 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PaperID                           Doi  \\\n",
       "37           14558443  10.1007/978-3-662-45174-8_28   \n",
       "39           15354235  10.1007/978-3-662-44777-2_60   \n",
       "2181       1459710595  10.1007/978-3-319-08958-4_17   \n",
       "2192       2161259116          10.1109/CVPR.2013.65   \n",
       "2523       1488332647   10.1109/ISBMSB.2008.4536671   \n",
       "...               ...                           ...   \n",
       "259717113  2789624042    10.1109/ISSCC.2018.8310368   \n",
       "259717694  2893506456  10.1007/978-3-030-01418-6_54   \n",
       "259717766  2914533952       10.1145/3308558.3313726   \n",
       "259717787  2921629601    10.1109/ICOSC.2019.8665672   \n",
       "259717991  2967304537     10.1109/ICRA.2019.8794157   \n",
       "\n",
       "                                                  PaperTitle  \\\n",
       "37         the adaptive priority queue with elimination a...   \n",
       "39              document retrieval on repetitive collections   \n",
       "2181       enhancing labeled data using unlabeled data fo...   \n",
       "2192       improved image set classification via joint sp...   \n",
       "2523       a novel channel estimation based on spread pil...   \n",
       "...                                                      ...   \n",
       "259717113  a 95 2 efficiency dual path dc dc step up conv...   \n",
       "259717694  learning preferences for large scale multi lab...   \n",
       "259717766  city wide signal strength maps prediction with...   \n",
       "259717787  constructing and maintaining corpus driven ann...   \n",
       "259717991  1 actuator 3 dof manipulation using an underac...   \n",
       "\n",
       "                                               OriginalTitle  Year  \\\n",
       "37         The Adaptive Priority Queue with Elimination a...  2014   \n",
       "39              Document Retrieval on Repetitive Collections  2014   \n",
       "2181       Enhancing Labeled Data Using Unlabeled Data fo...  2011   \n",
       "2192       Improved Image Set Classification via Joint Sp...  2013   \n",
       "2523       A novel channel estimation based on spread pil...  2008   \n",
       "...                                                      ...   ...   \n",
       "259717113  A 95.2% efficiency dual-path DC-DC step-up con...  2018   \n",
       "259717694  Learning Preferences for Large Scale Multi-lab...  2018   \n",
       "259717766  City-Wide Signal Strength Maps: Prediction wit...  2019   \n",
       "259717787  Constructing and Maintaining Corpus-Driven Ann...  2019   \n",
       "259717991  1-Actuator 3-DoF Manipulation Using an Underac...  2019   \n",
       "\n",
       "           ConferenceSeriesID  ConferenceInstanceID  CitationCount  \\\n",
       "37               1.131603e+09          4.038532e+06           12.0   \n",
       "39               1.154039e+09          1.570085e+08           10.0   \n",
       "2181             2.760407e+09          2.019264e+08            0.0   \n",
       "2192             1.158168e+09          1.383691e+08           75.0   \n",
       "2523             2.623662e+09          2.626942e+09            4.0   \n",
       "...                       ...                   ...            ...   \n",
       "259717113        1.183230e+09          2.788559e+09            8.0   \n",
       "259717694        1.158833e+09          2.892231e+09            1.0   \n",
       "259717766        1.135342e+09          2.890478e+09            8.0   \n",
       "259717787        2.898614e+09          2.889800e+09            1.0   \n",
       "259717991        1.163902e+09          2.891770e+09            0.0   \n",
       "\n",
       "          EstimatedCitation  \n",
       "37                       12  \n",
       "39                       10  \n",
       "2181                      0  \n",
       "2192                     95  \n",
       "2523                      4  \n",
       "...                     ...  \n",
       "259717113                 8  \n",
       "259717694                 1  \n",
       "259717766                 8  \n",
       "259717787                 1  \n",
       "259717991                 0  \n",
       "\n",
       "[1431517 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Filtering of papers without DOI\n",
    "df_mag_papers_cp = df_mag_papers\n",
    "df_mag_papers_cp = df_mag_papers_cp.dropna(subset = ['ConferenceInstanceID'])\n",
    "df_mag_papers_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PAPERS ********************\n",
    "\n",
    "# The Papers CSV is going to be processed in chunks, due to its size\n",
    "\n",
    "# The column names follow the MAG' scheme official documentation\n",
    "df_mag_papers_col_names = ['PaperID', 'Rank', 'Doi', 'DocType', 'PaperTitle', 'OriginalTitle', 'BookTitle', 'Year', 'Date', 'OnlineDate', 'Publisher', 'JournalID', 'ConferenceSeriesID', 'ConferenceInstanceID', 'Volume', 'Issue', 'FirstPage', 'LastPage', 'ReferenceCount', 'CitationCount', 'EstimatedCitation', 'OriginalVenue', 'FamilyID', 'FamilyRank', 'CreatedDate']\n",
    "\n",
    "# List of processed chunks.\n",
    "df_mag_papers_list_of_chunks = list()\n",
    "\n",
    "# Define of the chunk size\n",
    "chunksize = 10 ** 7\n",
    "\n",
    "count = 1\n",
    "with pd.read_csv(path_file_import + 'Papers.txt', sep='\\t', names=df_mag_papers_col_names, chunksize=chunksize, low_memory=False, on_bad_lines='skip') as reader:\n",
    "    for chunk in reader:\n",
    "        print(f'Currently processing chunk {count} out of around 400')\n",
    "        count += 1\n",
    "\n",
    "        # Drop of the useless columns\n",
    "        chunk = chunk.drop(columns=['Rank', 'OnlineDate', 'Publisher', 'Volume', 'Issue', 'FirstPage', 'LastPage', 'ReferenceCount', 'OriginalVenue', 'FamilyID', 'FamilyRank', 'CreatedDate'])\n",
    "\n",
    "        # Filtering of books and Journals papers\n",
    "        # TODO\n",
    "\n",
    "        # Insert of the resulting chunk in the list \n",
    "        df_mag_papers_list_of_chunks.append(chunk)\n",
    "\n",
    "# Concatenation of the processed chunks\n",
    "df_mag_papers = pd.concat(df_mag_papers_list_of_chunks)\n",
    "\n",
    "# Empty the list to free some memory\n",
    "df_mag_papers_list_of_chunks = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mag_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export of the partial dataframe\n",
    "df_mag_papers.to_csv(path_file_export + 'out_mag_citations_partial.csv')\n",
    "print(f'Successfully Exported the Partial Preprocessed CSV to {path_file_export}out_mag_citations_partial.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Files' Names\n",
    "coci_all_csvs = glob.glob(path_file_import + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coci_processed = pd.DataFrame(columns=['article', 'citations_count'])\n",
    "\n",
    "# Combine new data with a partial CSV\n",
    "if combine_with_partial_csv:\n",
    "    df_coci_processed = pd.read_csv(partial_csv_path, low_memory=False)\n",
    "    print(f'Successfully Imported the Partial CSV')\n",
    "    \n",
    "# Read, process and concat all CSVs\n",
    "count = 0\n",
    "for current_csv_name in coci_all_csvs:\n",
    "\n",
    "    # Open the current CSV\n",
    "    print(f'Currently processing CSV {count}: {current_csv_name}')\n",
    "    count += 1\n",
    "    df_coci_current_csv = pd.read_csv(current_csv_name, low_memory=False)\n",
    "\n",
    "    # Drop of the useless columns: 'oci', 'citing', 'creation', 'timespan', 'journal_sc', 'author_sc'\n",
    "    df_coci_current_csv.drop(columns=['oci', 'citing', 'creation', 'timespan', 'journal_sc', 'author_sc'])\n",
    "\n",
    "    # Group by cited article and count\n",
    "    sf_coci_current_grouped = df_coci_current_csv.groupby(['cited'])['cited'].count()\n",
    "\n",
    "    # Since the returned object is a Pandas Series type, we need to convert it to a Pandas dataframe\n",
    "    df_coci_current_csv = pd.DataFrame({'article':sf_coci_current_grouped.index, 'citations_count':sf_coci_current_grouped.values})\n",
    "\n",
    "    ### Concat with the data previously elaborated\n",
    "    df_coci_processed = pd.concat([df_coci_processed, df_coci_current_csv])\n",
    "\n",
    "    # Now we need to do a new group by and sum the citations_count to reduce the data\n",
    "    sf_coci_processed_grouped = df_coci_processed.groupby(['article'])['citations_count'].sum()\n",
    "    df_coci_processed = pd.DataFrame({'article':sf_coci_processed_grouped.index, 'citations_count':sf_coci_processed_grouped.values})\n",
    "\n",
    "# Export of the final dataframe\n",
    "df_coci_processed.to_csv(path_file_export + 'out_coci_citations_count.csv')\n",
    "print(f'Successfully Exported the Preprocessed CSV to {path_file_export}out_coci_citations_count.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of the Exported CSV\n",
    "df_coci_exported_csv = pd.read_csv(path_file_export + 'out_coci_citations_count.csv', low_memory=False)\n",
    "df_coci_exported_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by citations count descending to see the articles with the most citations\n",
    "df_coci_exported_csv = df_coci_exported_csv.sort_values(by='citations_count', ascending=False)\n",
    "df_coci_exported_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the total count of the citations contained in the extracted CSV\n",
    "df_coci_exported_csv['citations_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
