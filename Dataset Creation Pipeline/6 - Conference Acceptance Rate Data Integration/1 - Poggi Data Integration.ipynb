{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poggi's Conference Acceptance Rate Data Integration\n",
    "\n",
    "Jupyter Notebook for the processing and integration of the Conference Acceptance Rate Data obtained by Prof. Francesco Poggi, professor at the University of Modena and Reggio Emilia.\n",
    "\n",
    "*The CORE Conference Ranking provides assessments of major conferences in the computing disciplines.The rankings are managed by the CORE Executive Committee, with periodic rounds for submission of requests for addition or reranking of conferences. Decisions are made by academic committees based on objective data requested as part of the submission process.* (source: CORE)\n",
    "\n",
    "The data was obtained by web scraping and is provided in JSON format.\n",
    "____________________________________________________________\n",
    "\n",
    "For this process, the following CSV files are needed: ```out_citations_and_conferences_location_ready_v2.csv``` and the Conference Acceptance Rate JSON files. \n",
    "\n",
    "The first one must be generated running the Notebook ```1 - Citation and Locations Dataset Preparation.ipynb``` that is contained in the ```5 - Conference Locations Ranking Integration``` folder of this Repository.<br>\n",
    "Poggi's Conference Acceptance Rate JSON files can be downloaded from [here]().\n",
    "\n",
    "In particular, the following operations are going to be executed:\n",
    "* Opening of the CSV conference citations and locations dataset\n",
    "* (Sequential) Reading of the JSON files\n",
    "* Expansion of the JSON fields\n",
    "* Processing of the JSON data\n",
    "* Join of the different processed JSON data\n",
    "* Join between the distinct conference series name and the Conference Acceptance Rate Data\n",
    "\n",
    "Lastly, the processed dataset is going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n",
    "Please set your working directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Import/data_acceptance/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Preparation of the Citation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Imported the Conference Citations and Locations Ready CSV\n"
     ]
    }
   ],
   "source": [
    "df_citations_and_locations = pd.read_csv(path_file_export + 'out_citations_and_conferences_location_ready_v2.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the Conference Citations and Locations Ready CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitationCount_COCI</th>\n",
       "      <th>CitationCount_Mag</th>\n",
       "      <th>CitationCount_MagEstimated</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, Texas, United States</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>disc</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Lower Silesian Voivodeship, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>esa</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Tyrol, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>enter</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitationCount_COCI  CitationCount_Mag  CitationCount_MagEstimated  \\\n",
       "0                  10                 12                          12   \n",
       "1                   5                 10                          10   \n",
       "2                  11                 20                          20   \n",
       "\n",
       "                            ConferenceLocation ConferenceNormalizedName  \\\n",
       "0                 Austin, Texas, United States                disc 2014   \n",
       "1  Wrocław, Lower Silesian Voivodeship, Poland                 esa 2014   \n",
       "2                    Innsbruck, Tyrol, Austria               enter 2013   \n",
       "\n",
       "  ConferenceSeriesNormalizedName                           Doi  Year  \n",
       "0                           disc  10.1007/978-3-662-45174-8_28  2014  \n",
       "1                            esa  10.1007/978-3-662-44777-2_60  2014  \n",
       "2                          enter  10.1007/978-3-319-03973-2_13  2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracion of the Distinct Conference Series from the Conference and Locations Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dexa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icaisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>calculemus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>agp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>sapere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5312 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ConferenceSeriesNormalizedName\n",
       "0                              disc\n",
       "1                               esa\n",
       "2                             enter\n",
       "3                              dexa\n",
       "4                            icaisc\n",
       "...                             ...\n",
       "5307                       infinity\n",
       "5308                     calculemus\n",
       "5309                            agp\n",
       "5310                            sci\n",
       "5311                         sapere\n",
       "\n",
       "[5312 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conference_series = df_citations_and_locations.drop_duplicates(subset=\"ConferenceSeriesNormalizedName\")\n",
    "\n",
    "#filter of the useless columns\n",
    "df_conference_series = df_conference_series.drop(df_conference_series.columns.difference([\"ConferenceSeriesNormalizedName\"]), axis=1)\n",
    "\n",
    "# drop of the nan row\n",
    "df_conference_series = df_conference_series.dropna(subset={\"ConferenceSeriesNormalizedName\"})\n",
    "\n",
    "# reset of the index\n",
    "df_conference_series = df_conference_series.reset_index(drop=True)\n",
    "\n",
    "df_conference_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Structure of the JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Imported the AcmConferences JSON\n"
     ]
    }
   ],
   "source": [
    "df_AcmConferences_raw = pd.read_json(path_file_import + 'AcmConferences.json')\n",
    "print(f'Successfully Imported the AcmConferences JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print of the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confName</th>\n",
       "      <th>confAcronym</th>\n",
       "      <th>confUrl</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DocEng: Document Engineering</td>\n",
       "      <td>DocEng</td>\n",
       "      <td>https://dl.acm.org/action/doSearch?target=brow...</td>\n",
       "      <td>[{'year': '19', 'yearUnparsed': 'DocEng '19', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANPU: Comics Aanalysis, Processing and Unders...</td>\n",
       "      <td>MANPU</td>\n",
       "      <td>https://dl.acm.org/action/doSearch?target=brow...</td>\n",
       "      <td>[{'year': '16', 'yearUnparsed': 'MANPU '16', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nanoarch: Nanoscale Architectures</td>\n",
       "      <td>Nanoarch</td>\n",
       "      <td>https://dl.acm.org/action/doSearch?target=brow...</td>\n",
       "      <td>[{'year': '18', 'yearUnparsed': 'NANOARCH '18'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            confName confAcronym  \\\n",
       "0                       DocEng: Document Engineering      DocEng   \n",
       "1  MANPU: Comics Aanalysis, Processing and Unders...       MANPU   \n",
       "2                  Nanoarch: Nanoscale Architectures    Nanoarch   \n",
       "\n",
       "                                             confUrl  \\\n",
       "0  https://dl.acm.org/action/doSearch?target=brow...   \n",
       "1  https://dl.acm.org/action/doSearch?target=brow...   \n",
       "2  https://dl.acm.org/action/doSearch?target=brow...   \n",
       "\n",
       "                                                info  \n",
       "0  [{'year': '19', 'yearUnparsed': 'DocEng '19', ...  \n",
       "1  [{'year': '16', 'yearUnparsed': 'MANPU '16', '...  \n",
       "2  [{'year': '18', 'yearUnparsed': 'NANOARCH '18'...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AcmConferences_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion of the info field\n",
    "The following stuff was only needed to understand the structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'year': '19', 'yearUnparsed': 'DocEng '19', '...</td>\n",
       "      <td>{'year': '17', 'yearUnparsed': 'DocEng '17', '...</td>\n",
       "      <td>{'year': '16', 'yearUnparsed': 'DocEng '16', '...</td>\n",
       "      <td>{'year': '15', 'yearUnparsed': 'DocEng '15', '...</td>\n",
       "      <td>{'year': '14', 'yearUnparsed': 'DocEng '14', '...</td>\n",
       "      <td>{'year': '13', 'yearUnparsed': 'DocEng '13', '...</td>\n",
       "      <td>{'year': '12', 'yearUnparsed': 'DocEng '12', '...</td>\n",
       "      <td>{'year': '11', 'yearUnparsed': 'DocEng '11', '...</td>\n",
       "      <td>{'year': '10', 'yearUnparsed': 'DocEng '10', '...</td>\n",
       "      <td>{'year': '09', 'yearUnparsed': 'DocEng '09', '...</td>\n",
       "      <td>{'year': '08', 'yearUnparsed': 'DocEng '08', '...</td>\n",
       "      <td>{'year': '07', 'yearUnparsed': 'DocEng '07', '...</td>\n",
       "      <td>{'year': '06', 'yearUnparsed': 'DocEng '06', '...</td>\n",
       "      <td>{'year': '05', 'yearUnparsed': 'DocEng '05', '...</td>\n",
       "      <td>{'year': '04', 'yearUnparsed': 'DocEng '04', '...</td>\n",
       "      <td>{'year': '03', 'yearUnparsed': 'DocEng '03', '...</td>\n",
       "      <td>{'year': '02', 'yearUnparsed': 'DocEng '02', '...</td>\n",
       "      <td>{'year': '01', 'yearUnparsed': 'DocEng '01', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0  {'year': '19', 'yearUnparsed': 'DocEng '19', '...   \n",
       "\n",
       "                                                  1   \\\n",
       "0  {'year': '17', 'yearUnparsed': 'DocEng '17', '...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  {'year': '16', 'yearUnparsed': 'DocEng '16', '...   \n",
       "\n",
       "                                                  3   \\\n",
       "0  {'year': '15', 'yearUnparsed': 'DocEng '15', '...   \n",
       "\n",
       "                                                  4   \\\n",
       "0  {'year': '14', 'yearUnparsed': 'DocEng '14', '...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  {'year': '13', 'yearUnparsed': 'DocEng '13', '...   \n",
       "\n",
       "                                                  6   \\\n",
       "0  {'year': '12', 'yearUnparsed': 'DocEng '12', '...   \n",
       "\n",
       "                                                  7   \\\n",
       "0  {'year': '11', 'yearUnparsed': 'DocEng '11', '...   \n",
       "\n",
       "                                                  8   \\\n",
       "0  {'year': '10', 'yearUnparsed': 'DocEng '10', '...   \n",
       "\n",
       "                                                  9   \\\n",
       "0  {'year': '09', 'yearUnparsed': 'DocEng '09', '...   \n",
       "\n",
       "                                                  10  \\\n",
       "0  {'year': '08', 'yearUnparsed': 'DocEng '08', '...   \n",
       "\n",
       "                                                  11  \\\n",
       "0  {'year': '07', 'yearUnparsed': 'DocEng '07', '...   \n",
       "\n",
       "                                                  12  \\\n",
       "0  {'year': '06', 'yearUnparsed': 'DocEng '06', '...   \n",
       "\n",
       "                                                  13  \\\n",
       "0  {'year': '05', 'yearUnparsed': 'DocEng '05', '...   \n",
       "\n",
       "                                                  14  \\\n",
       "0  {'year': '04', 'yearUnparsed': 'DocEng '04', '...   \n",
       "\n",
       "                                                  15  \\\n",
       "0  {'year': '03', 'yearUnparsed': 'DocEng '03', '...   \n",
       "\n",
       "                                                  16  \\\n",
       "0  {'year': '02', 'yearUnparsed': 'DocEng '02', '...   \n",
       "\n",
       "                                                  17  \n",
       "0  {'year': '01', 'yearUnparsed': 'DocEng '01', '...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_level = pd.json_normalize(df_AcmConferences_raw.iloc[[0]]['info'])\n",
    "df_first_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>yearUnparsed</th>\n",
       "      <th>yearUrl</th>\n",
       "      <th>submitted</th>\n",
       "      <th>accepted</th>\n",
       "      <th>percAccepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>DocEng '19</td>\n",
       "      <td>https://dl.acm.org/doi/proceedings/10.1145/334...</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "      <td>39%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  year yearUnparsed                                            yearUrl  \\\n",
       "0   19   DocEng '19  https://dl.acm.org/doi/proceedings/10.1145/334...   \n",
       "\n",
       "  submitted accepted percAccepted  \n",
       "0        77       30          39%  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(df_first_level.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of the JSON Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the JSON Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the processing function (is going to be used for all the different datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_dataframe(raw_dataframe):\n",
    "    out_row_list = list()\n",
    "\n",
    "    for index, row in raw_dataframe.iterrows():\n",
    "\n",
    "        # expansion from the info field\n",
    "        df_first_level = pd.json_normalize(row['info'])\n",
    "\n",
    "        for index_first_level, row_first_level in df_first_level.iterrows():\n",
    "            # check if there's the year\n",
    "            try:\n",
    "                row_first_level['year'] \n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # check if there's the percAccepted\n",
    "            try:\n",
    "                row_first_level['percAccepted'] \n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            # filter of null rows\n",
    "            if pd.isnull(row_first_level['year']) or pd.isnull(row_first_level['percAccepted']) or pd.isnull(row_first_level['submitted']) or pd.isnull(row_first_level['accepted']):\n",
    "                continue # skip row\n",
    "\n",
    "            # filter of some year special cases\n",
    "            if isinstance(row_first_level['year'], str):\n",
    "                if row_first_level['year'].__len__() > 4: # special case like \"19 Companion\", that we need to filter\n",
    "                    continue # skip row\n",
    "\n",
    "            # filter of some invalid data\n",
    "            if \"?\" in str(row_first_level['submitted']) or \"?\" in str(row_first_level['accepted']) or \"?\" in str(row_first_level['percAccepted']):\n",
    "                continue # skip row\n",
    "\n",
    "            # normalization of the year format\n",
    "            year = int(row_first_level['year'])\n",
    "            if year < 100: # two figures\n",
    "                year = 2000 + year\n",
    "\n",
    "            # creation of the support dataframe\n",
    "            support_dict = dict()\n",
    "            support_dict['Conf_Acronym'] = row['confAcronym'].lower()\n",
    "            support_dict['Year'] = year\n",
    "\n",
    "            # removing points or commas \n",
    "            submitted_str = str(row_first_level['submitted']).split(\".\")[0].split(\",\")[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].split(\"(\")[0]\n",
    "            if \"~\" in submitted_str:\n",
    "                submitted_str = submitted_str.split(\"~\")[1]\n",
    "            submitted_str = submitted_str.strip()\n",
    "            if submitted_str.__len__() == 0 or \"--\" in submitted_str or not submitted_str.isnumeric():\n",
    "                continue # skip row\n",
    "            submitted = int(submitted_str)\n",
    "\n",
    "            accepted_str = str(row_first_level['accepted']).split(\".\")[0].split(\",\")[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].split(\"(\")[0]\n",
    "            if \":\" in accepted_str:\n",
    "                accepted_str = accepted_str.split(\":\")[1]\n",
    "            if \"~\" in accepted_str:\n",
    "                accepted_str = accepted_str.split(\"~\")[1]\n",
    "            accepted_str = accepted_str.strip()\n",
    "            if accepted_str.__len__() == 0 or \"--\" in accepted_str or not accepted_str.isnumeric():\n",
    "                continue # skip row\n",
    "            accepted = int(accepted_str)\n",
    "                \n",
    "\n",
    "            perc_accepted_str = str(row_first_level['percAccepted']).split('%')[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].replace(\",\", \".\")\n",
    "            if perc_accepted_str.__len__() == 0:\n",
    "                continue # skip row\n",
    "            if \"~\" in perc_accepted_str:\n",
    "                perc_accepted = float(perc_accepted_str.split(\"~\")[1])\n",
    "            else:\n",
    "                perc_accepted = float(perc_accepted_str)\n",
    "\n",
    "            support_dict['Papers_Submitted'] = submitted\n",
    "            support_dict['Papers_Accepted'] = accepted\n",
    "            support_dict['Papers_Perc_Accepted'] = perc_accepted\n",
    "            \n",
    "            # putting the values inside our output list\n",
    "            out_row_list.append(support_dict)\n",
    "\n",
    "    # conversion of the output list to a dataframe\n",
    "    return pd.DataFrame(out_row_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_dataframe_with_file_name(raw_dataframe, file_name):\n",
    "    out_row_list = list()\n",
    "\n",
    "    for index, row in raw_dataframe.iterrows():\n",
    "\n",
    "        # expansion from the info field\n",
    "        df_first_level = pd.json_normalize(row['info'])\n",
    "\n",
    "        for index_first_level, row_first_level in df_first_level.iterrows():\n",
    "            # check if there's the year\n",
    "            try:\n",
    "                row_first_level['year'] \n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # check if there's the percAccepted\n",
    "            try:\n",
    "                row_first_level['percAccepted'] \n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            # filter of null rows\n",
    "            if pd.isnull(row_first_level['year']) or pd.isnull(row_first_level['percAccepted']) or pd.isnull(row_first_level['submitted']) or pd.isnull(row_first_level['accepted']):\n",
    "                continue # skip row\n",
    "\n",
    "            # filter of some year special cases\n",
    "            if isinstance(row_first_level['year'], str):\n",
    "                if row_first_level['year'].__len__() > 4: # special case like \"19 Companion\", that we need to filter\n",
    "                    continue # skip row\n",
    "\n",
    "            # filter of some invalid data\n",
    "            if \"?\" in str(row_first_level['submitted']) or \"?\" in str(row_first_level['accepted']) or \"?\" in str(row_first_level['percAccepted']):\n",
    "                continue # skip row\n",
    "\n",
    "            # normalization of the year format\n",
    "            year = int(row_first_level['year'])\n",
    "            if year < 100: # two figures\n",
    "                year = 2000 + year\n",
    "\n",
    "            # creation of the support dataframe\n",
    "            support_dict = dict()\n",
    "            support_dict['Conf_Acronym'] = row['confAcronym'].lower()\n",
    "            support_dict['Year'] = year\n",
    "\n",
    "            # removing points or commas \n",
    "            submitted_str = str(row_first_level['submitted']).split(\".\")[0].split(\",\")[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].split(\"(\")[0]\n",
    "            if \"~\" in submitted_str:\n",
    "                submitted_str = submitted_str.split(\"~\")[1]\n",
    "            submitted_str = submitted_str.strip()\n",
    "            if submitted_str.__len__() == 0 or \"--\" in submitted_str or not submitted_str.isnumeric():\n",
    "                continue # skip row\n",
    "            submitted = int(submitted_str)\n",
    "\n",
    "            accepted_str = str(row_first_level['accepted']).split(\".\")[0].split(\",\")[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].split(\"(\")[0]\n",
    "            if \":\" in accepted_str:\n",
    "                accepted_str = accepted_str.split(\":\")[1]\n",
    "            if \"~\" in accepted_str:\n",
    "                accepted_str = accepted_str.split(\"~\")[1]\n",
    "            accepted_str = accepted_str.strip()\n",
    "            if accepted_str.__len__() == 0 or \"--\" in accepted_str or not accepted_str.isnumeric():\n",
    "                continue # skip row\n",
    "            accepted = int(accepted_str)\n",
    "                \n",
    "\n",
    "            perc_accepted_str = str(row_first_level['percAccepted']).split('%')[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].replace(\",\", \".\")\n",
    "            if perc_accepted_str.__len__() == 0:\n",
    "                continue # skip row\n",
    "            if \"~\" in perc_accepted_str:\n",
    "                perc_accepted = float(perc_accepted_str.split(\"~\")[1])\n",
    "            else:\n",
    "                perc_accepted = float(perc_accepted_str)\n",
    "\n",
    "            support_dict['Papers_Submitted' + '_' + file_name] = submitted\n",
    "            support_dict['Papers_Accepted' + '_' + file_name] = accepted\n",
    "            support_dict['Papers_Perc_Accepted' + '_' + file_name] = perc_accepted\n",
    "            \n",
    "            # putting the values inside our output list\n",
    "            out_row_list.append(support_dict)\n",
    "\n",
    "    # conversion of the output list to a dataframe\n",
    "    return pd.DataFrame(out_row_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Reading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing JSON: CryptographyConferencesStatistics.json\n",
      "Currently processing JSON: TheoreticalCSConferencesStatistics.json\n",
      "Currently processing JSON: NetworkingConferencesStatistics.json\n",
      "Currently processing JSON: AcmConferences.json\n",
      "Currently processing JSON: SEConferencesStatistics.json\n",
      "Currently processing JSON: ComputerSecurityConferencesStatistics.json\n"
     ]
    }
   ],
   "source": [
    "output_dataframes_list = list()\n",
    "\n",
    "poggis_all_jsons = glob.glob(path_file_import + \"*.json\")\n",
    "\n",
    "for current_json_name_full in poggis_all_jsons:\n",
    "\n",
    "    current_json_name = current_json_name_full.split(\"/\")[-1]\n",
    "\n",
    "    # Open the current CSV\n",
    "    print(f'Currently processing JSON: {current_json_name}')\n",
    "    df_current_json = pd.read_json(current_json_name_full)\n",
    "\n",
    "    # Processing of the json file\n",
    "    output_dataframes_list.append(process_json_dataframe(df_current_json))\n",
    "    #output_dataframes_list.append(process_json_dataframe_with_file_name(df_current_json, current_json_name.split('.json')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the first processed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Conf_Acronym  Year  Papers_Submitted_CryptographyConferencesStatistics  \\\n",
      "0         crypto  2014                                                227    \n",
      "1         crypto  2013                                                227    \n",
      "2         crypto  2012                                                225    \n",
      "3         crypto  2011                                                230    \n",
      "4         crypto  2010                                                202    \n",
      "..           ...   ...                                                ...    \n",
      "122          tcc  2010                                                100    \n",
      "123          tcc  2009                                                109    \n",
      "124          tcc  2008                                                 81    \n",
      "125          tcc  2007                                                118    \n",
      "126          tcc  2006                                                 91    \n",
      "\n",
      "     Papers_Accepted_CryptographyConferencesStatistics  \\\n",
      "0                                                   60   \n",
      "1                                                   61   \n",
      "2                                                   48   \n",
      "3                                                   42   \n",
      "4                                                   39   \n",
      "..                                                 ...   \n",
      "122                                                 33   \n",
      "123                                                 33   \n",
      "124                                                 33   \n",
      "125                                                 31   \n",
      "126                                                 31   \n",
      "\n",
      "     Papers_Perc_Accepted_CryptographyConferencesStatistics  \n",
      "0                                                 26.4       \n",
      "1                                                 26.9       \n",
      "2                                                 21.3       \n",
      "3                                                 18.3       \n",
      "4                                                 19.3       \n",
      "..                                                 ...       \n",
      "122                                               33.0       \n",
      "123                                               30.3       \n",
      "124                                               40.7       \n",
      "125                                               26.3       \n",
      "126                                               34.1       \n",
      "\n",
      "[127 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "if output_dataframes_list.__len__() > 0:\n",
    "    print(output_dataframes_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Between the Different Processed JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_dataframes_list.__len__() >= 1:\n",
    "    df_conference_acceptance_rate_joined = output_dataframes_list[0]\n",
    "\n",
    "    for i in range (1, output_dataframes_list.__len__() - 1):\n",
    "        df_conference_acceptance_rate_joined = pd.merge(df_conference_acceptance_rate_joined, output_dataframes_list[i], on=['Conf_Acronym', 'Year'], how='outer')\n",
    "\n",
    "        # Combine the Papers_Submitted columns\n",
    "        df_conference_acceptance_rate_joined['Papers_Submitted_x'] = df_conference_acceptance_rate_joined['Papers_Submitted_x'].fillna(df_conference_acceptance_rate_joined['Papers_Submitted_y'])\n",
    "        df_conference_acceptance_rate_joined.rename(columns = {'Papers_Submitted_x':'Papers_Submitted'}, inplace=True)\n",
    "        df_conference_acceptance_rate_joined = df_conference_acceptance_rate_joined.drop(columns=['Papers_Submitted_y'])\n",
    "\n",
    "        # Combine the Papers_Accepted columns\n",
    "        df_conference_acceptance_rate_joined['Papers_Accepted_x'] = df_conference_acceptance_rate_joined['Papers_Accepted_x'].fillna(df_conference_acceptance_rate_joined['Papers_Accepted_y'])\n",
    "        df_conference_acceptance_rate_joined.rename(columns = {'Papers_Accepted_x':'Papers_Accepted'}, inplace=True)\n",
    "        df_conference_acceptance_rate_joined = df_conference_acceptance_rate_joined.drop(columns=['Papers_Accepted_y'])\n",
    "\n",
    "        # Combine the Papers_Perc_Accepted columns\n",
    "        df_conference_acceptance_rate_joined['Papers_Perc_Accepted_x'] = df_conference_acceptance_rate_joined['Papers_Perc_Accepted_x'].fillna(df_conference_acceptance_rate_joined['Papers_Perc_Accepted_y'])\n",
    "        df_conference_acceptance_rate_joined.rename(columns = {'Papers_Perc_Accepted_x':'Papers_Perc_Accepted'}, inplace=True)\n",
    "        df_conference_acceptance_rate_joined = df_conference_acceptance_rate_joined.drop(columns=['Papers_Perc_Accepted_y'])\n",
    "\n",
    "    # Column sort\n",
    "    df_conference_acceptance_rate_joined = df_conference_acceptance_rate_joined.reindex(sorted(df_conference_acceptance_rate_joined.columns), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conf_Acronym</th>\n",
       "      <th>Papers_Accepted</th>\n",
       "      <th>Papers_Perc_Accepted</th>\n",
       "      <th>Papers_Submitted</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crypto</td>\n",
       "      <td>60.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crypto</td>\n",
       "      <td>61.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crypto</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crypto</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>230.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crypto</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>policy</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7091</th>\n",
       "      <td>policy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7092</th>\n",
       "      <td>policy</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>fmse</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>fmse</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7095 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Conf_Acronym  Papers_Accepted  Papers_Perc_Accepted  Papers_Submitted  \\\n",
       "0          crypto             60.0                  26.4             227.0   \n",
       "1          crypto             61.0                  26.9             227.0   \n",
       "2          crypto             48.0                  21.3             225.0   \n",
       "3          crypto             42.0                  18.3             230.0   \n",
       "4          crypto             39.0                  19.3             202.0   \n",
       "...           ...              ...                   ...               ...   \n",
       "7090       policy             18.0                  31.0              59.0   \n",
       "7091       policy             20.0                  22.0              90.0   \n",
       "7092       policy             18.0                  21.0              87.0   \n",
       "7093         fmse              8.0                  36.0              22.0   \n",
       "7094         fmse              9.0                  36.0              25.0   \n",
       "\n",
       "      Year  \n",
       "0     2014  \n",
       "1     2013  \n",
       "2     2012  \n",
       "3     2011  \n",
       "4     2010  \n",
       "...    ...  \n",
       "7090  2006  \n",
       "7091  2005  \n",
       "7092  2004  \n",
       "7093  2005  \n",
       "7094  2004  \n",
       "\n",
       "[7095 rows x 5 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conference_acceptance_rate_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mag = pd.merge(df_mag, df_dblp, on=['Doi'], how='outer')\n",
    "\n",
    "# Combine the conference location columns\n",
    "df_mag['ConferenceLocation_x'] = df_mag['ConferenceLocation_x'].fillna(df_mag['ConferenceLocation_y'])\n",
    "df_mag.rename(columns = {'ConferenceLocation_x':'ConferenceLocation'}, inplace=True)\n",
    "df_mag = df_mag.drop(columns=['ConferenceLocation_y'])\n",
    "\n",
    "# Combine the conference normalized name columns\n",
    "df_mag['ConferenceNormalizedName_x'] = df_mag['ConferenceNormalizedName_x'].fillna(df_mag['ConferenceNormalizedName_y'])\n",
    "df_mag.rename(columns = {'ConferenceNormalizedName_x':'ConferenceNormalizedName'}, inplace=True)\n",
    "df_mag = df_mag.drop(columns=['ConferenceNormalizedName_y'])\n",
    "\n",
    "# Combine the year columns\n",
    "df_mag['Year'] = df_mag['Year'].fillna(df_mag['year'])\n",
    "df_mag = df_mag.drop(columns=['year'])\n",
    "\n",
    "# Drop of the DBLP columns that are not needed anymore\n",
    "df_mag = df_mag.drop(columns=['crossref', 'ee', 'key', 'url'])\n",
    "\n",
    "# Drop of the MAG columns that are not needed anymore\n",
    "df_mag = df_mag.drop(columns=['PaperTitle', 'ConferenceSeriesDisplayName', 'ConferenceSeriesNormalizedName'])\n",
    "\n",
    "# Rename of some columns to remove ambiguity\n",
    "df_mag.rename(columns={'CitationCount': 'CitationCount_Mag', 'EstimatedCitation': 'CitationCount_MagEstimated'}, inplace=True)\n",
    "\n",
    "# Column sort\n",
    "df_mag = df_mag.reindex(sorted(df_mag.columns), axis=1)\n",
    "\n",
    "# Fix of the year column data type\n",
    "df_mag = df_mag.astype({\"Year\": int}) \n",
    "\n",
    "df_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write of the Final CSVs on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the resulting dataframe on disk in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Exported the Joined CSV to /Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/out_conference_series_with_core_rank.csv\n"
     ]
    }
   ],
   "source": [
    "# Write of the resulting CSVs on Disk\n",
    "df_conference_series_with_core_rank.to_csv(path_file_export + 'out_conference_series_with_core_rank.csv')\n",
    "print(f'Successfully Exported the Joined CSV to {path_file_export}out_conference_series_with_core_rank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the Exported CSV to be sure that everything went fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORE_2008_Rank</th>\n",
       "      <th>CORE_2013_Rank</th>\n",
       "      <th>CORE_2014_Rank</th>\n",
       "      <th>CORE_2017_Rank</th>\n",
       "      <th>CORE_2018_Rank</th>\n",
       "      <th>CORE_2020_Rank</th>\n",
       "      <th>CORE_2021_Rank</th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "      <th>ERA_2010_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>disc</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>esa</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>enter</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>dexa</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>icaisc</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>infinity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>calculemus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>agp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sci</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sapere</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5312 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CORE_2008_Rank CORE_2013_Rank CORE_2014_Rank CORE_2017_Rank  \\\n",
       "0                 A              A              A              A   \n",
       "1                 A              A              A              A   \n",
       "2               NaN              C              C              C   \n",
       "3                 A              B              B              B   \n",
       "4               NaN              C              C              C   \n",
       "...             ...            ...            ...            ...   \n",
       "5307            NaN            NaN            NaN            NaN   \n",
       "5308            NaN            NaN            NaN            NaN   \n",
       "5309            NaN            NaN            NaN            NaN   \n",
       "5310            NaN            NaN            NaN            NaN   \n",
       "5311            NaN            NaN            NaN            NaN   \n",
       "\n",
       "     CORE_2018_Rank CORE_2020_Rank CORE_2021_Rank  \\\n",
       "0                 A              A              A   \n",
       "1                 A              A              A   \n",
       "2                 C              C              C   \n",
       "3                 B              B              B   \n",
       "4                 C            NaN            NaN   \n",
       "...             ...            ...            ...   \n",
       "5307            NaN            NaN            NaN   \n",
       "5308            NaN            NaN            NaN   \n",
       "5309            NaN            NaN            NaN   \n",
       "5310            NaN            NaN            NaN   \n",
       "5311            NaN            NaN            NaN   \n",
       "\n",
       "     ConferenceSeriesNormalizedName ERA_2010_Rank  \n",
       "0                              disc             A  \n",
       "1                               esa             A  \n",
       "2                             enter             C  \n",
       "3                              dexa             B  \n",
       "4                            icaisc             C  \n",
       "...                             ...           ...  \n",
       "5307                       infinity           NaN  \n",
       "5308                     calculemus           NaN  \n",
       "5309                            agp           NaN  \n",
       "5310                            sci           NaN  \n",
       "5311                         sapere           NaN  \n",
       "\n",
       "[5312 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check of the Exported CSV\n",
    "df_conference_series_with_core_rank = pd.read_csv(path_file_export + 'out_conference_series_with_core_rank.csv', low_memory=False, index_col=[0])\n",
    "df_conference_series_with_core_rank"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
