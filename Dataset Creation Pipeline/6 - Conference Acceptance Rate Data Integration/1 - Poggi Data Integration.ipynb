{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poggi's Conference Acceptance Rate Data Integration\n",
    "\n",
    "Jupyter Notebook for the processing and integration of the Conference Acceptance Rate Data obtained by Prof. Francesco Poggi, professor at the University of Modena and Reggio Emilia.\n",
    "\n",
    "*The CORE Conference Ranking provides assessments of major conferences in the computing disciplines.The rankings are managed by the CORE Executive Committee, with periodic rounds for submission of requests for addition or reranking of conferences. Decisions are made by academic committees based on objective data requested as part of the submission process.* (source: CORE)\n",
    "\n",
    "The data was obtained by web scraping and is provided in JSON format.\n",
    "____________________________________________________________\n",
    "\n",
    "For this process, the following CSV files are needed: ```out_citations_and_conferences_location_ready_v2.csv``` and the Conference Acceptance Rate JSON files. \n",
    "\n",
    "The first one must be generated running the Notebook ```1 - Citation and Locations Dataset Preparation.ipynb``` that is contained in the ```5 - Conference Locations Ranking Integration``` folder of this Repository.<br>\n",
    "Poggi's Conference Acceptance Rate JSON files can be downloaded from [here]().\n",
    "\n",
    "In particular, the following operations are going to be executed:\n",
    "* Opening of the CSV conference citations and locations dataset\n",
    "* (Sequential) Reading of the JSON files\n",
    "* Expansion of the JSON fields\n",
    "* Processing of the JSON data\n",
    "* Join of the different processed JSON data\n",
    "* Join between the distinct conference series name and the Conference Acceptance Rate Data\n",
    "\n",
    "Lastly, the processed dataset is going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n",
    "Please set your working directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Import/data_acceptance/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Preparation of the Citation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Imported the Conference Citations and Locations Ready CSV\n"
     ]
    }
   ],
   "source": [
    "df_citations_and_locations = pd.read_csv(path_file_export + 'out_citations_and_conferences_location_ready_v2.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the Conference Citations and Locations Ready CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitationCount_COCI</th>\n",
       "      <th>CitationCount_Mag</th>\n",
       "      <th>CitationCount_MagEstimated</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, Texas, United States</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>disc</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Lower Silesian Voivodeship, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>esa</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Tyrol, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>enter</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitationCount_COCI  CitationCount_Mag  CitationCount_MagEstimated  \\\n",
       "0                  10                 12                          12   \n",
       "1                   5                 10                          10   \n",
       "2                  11                 20                          20   \n",
       "\n",
       "                            ConferenceLocation ConferenceNormalizedName  \\\n",
       "0                 Austin, Texas, United States                disc 2014   \n",
       "1  Wrocław, Lower Silesian Voivodeship, Poland                 esa 2014   \n",
       "2                    Innsbruck, Tyrol, Austria               enter 2013   \n",
       "\n",
       "  ConferenceSeriesNormalizedName                           Doi  Year  \n",
       "0                           disc  10.1007/978-3-662-45174-8_28  2014  \n",
       "1                            esa  10.1007/978-3-662-44777-2_60  2014  \n",
       "2                          enter  10.1007/978-3-319-03973-2_13  2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracion of the Distinct Conference Series from the Conference and Locations Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dexa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icaisc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>calculemus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>agp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>sapere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5312 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ConferenceSeriesNormalizedName\n",
       "0                              disc\n",
       "1                               esa\n",
       "2                             enter\n",
       "3                              dexa\n",
       "4                            icaisc\n",
       "...                             ...\n",
       "5307                       infinity\n",
       "5308                     calculemus\n",
       "5309                            agp\n",
       "5310                            sci\n",
       "5311                         sapere\n",
       "\n",
       "[5312 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conference_series = df_citations_and_locations.drop_duplicates(subset=\"ConferenceSeriesNormalizedName\")\n",
    "\n",
    "#filter of the useless columns\n",
    "df_conference_series = df_conference_series.drop(df_conference_series.columns.difference([\"ConferenceSeriesNormalizedName\"]), axis=1)\n",
    "\n",
    "# drop of the nan row\n",
    "df_conference_series = df_conference_series.dropna(subset={\"ConferenceSeriesNormalizedName\"})\n",
    "\n",
    "# reset of the index\n",
    "df_conference_series = df_conference_series.reset_index(drop=True)\n",
    "\n",
    "df_conference_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Structure of the JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Imported the AcmConferences JSON\n"
     ]
    }
   ],
   "source": [
    "df_AcmConferences_raw = pd.read_json(path_file_import + 'AcmConferences.json')\n",
    "print(f'Successfully Imported the AcmConferences JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print of the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confName</th>\n",
       "      <th>confAcronym</th>\n",
       "      <th>confUrl</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DocEng: Document Engineering</td>\n",
       "      <td>DocEng</td>\n",
       "      <td>https://dl.acm.org/action/doSearch?target=brow...</td>\n",
       "      <td>[{'year': '19', 'yearUnparsed': 'DocEng '19', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANPU: Comics Aanalysis, Processing and Unders...</td>\n",
       "      <td>MANPU</td>\n",
       "      <td>https://dl.acm.org/action/doSearch?target=brow...</td>\n",
       "      <td>[{'year': '16', 'yearUnparsed': 'MANPU '16', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nanoarch: Nanoscale Architectures</td>\n",
       "      <td>Nanoarch</td>\n",
       "      <td>https://dl.acm.org/action/doSearch?target=brow...</td>\n",
       "      <td>[{'year': '18', 'yearUnparsed': 'NANOARCH '18'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            confName confAcronym  \\\n",
       "0                       DocEng: Document Engineering      DocEng   \n",
       "1  MANPU: Comics Aanalysis, Processing and Unders...       MANPU   \n",
       "2                  Nanoarch: Nanoscale Architectures    Nanoarch   \n",
       "\n",
       "                                             confUrl  \\\n",
       "0  https://dl.acm.org/action/doSearch?target=brow...   \n",
       "1  https://dl.acm.org/action/doSearch?target=brow...   \n",
       "2  https://dl.acm.org/action/doSearch?target=brow...   \n",
       "\n",
       "                                                info  \n",
       "0  [{'year': '19', 'yearUnparsed': 'DocEng '19', ...  \n",
       "1  [{'year': '16', 'yearUnparsed': 'MANPU '16', '...  \n",
       "2  [{'year': '18', 'yearUnparsed': 'NANOARCH '18'...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AcmConferences_raw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansion of the info field\n",
    "The following stuff was only needed to understand the structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'year': '19', 'yearUnparsed': 'DocEng '19', '...</td>\n",
       "      <td>{'year': '17', 'yearUnparsed': 'DocEng '17', '...</td>\n",
       "      <td>{'year': '16', 'yearUnparsed': 'DocEng '16', '...</td>\n",
       "      <td>{'year': '15', 'yearUnparsed': 'DocEng '15', '...</td>\n",
       "      <td>{'year': '14', 'yearUnparsed': 'DocEng '14', '...</td>\n",
       "      <td>{'year': '13', 'yearUnparsed': 'DocEng '13', '...</td>\n",
       "      <td>{'year': '12', 'yearUnparsed': 'DocEng '12', '...</td>\n",
       "      <td>{'year': '11', 'yearUnparsed': 'DocEng '11', '...</td>\n",
       "      <td>{'year': '10', 'yearUnparsed': 'DocEng '10', '...</td>\n",
       "      <td>{'year': '09', 'yearUnparsed': 'DocEng '09', '...</td>\n",
       "      <td>{'year': '08', 'yearUnparsed': 'DocEng '08', '...</td>\n",
       "      <td>{'year': '07', 'yearUnparsed': 'DocEng '07', '...</td>\n",
       "      <td>{'year': '06', 'yearUnparsed': 'DocEng '06', '...</td>\n",
       "      <td>{'year': '05', 'yearUnparsed': 'DocEng '05', '...</td>\n",
       "      <td>{'year': '04', 'yearUnparsed': 'DocEng '04', '...</td>\n",
       "      <td>{'year': '03', 'yearUnparsed': 'DocEng '03', '...</td>\n",
       "      <td>{'year': '02', 'yearUnparsed': 'DocEng '02', '...</td>\n",
       "      <td>{'year': '01', 'yearUnparsed': 'DocEng '01', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0  {'year': '19', 'yearUnparsed': 'DocEng '19', '...   \n",
       "\n",
       "                                                  1   \\\n",
       "0  {'year': '17', 'yearUnparsed': 'DocEng '17', '...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  {'year': '16', 'yearUnparsed': 'DocEng '16', '...   \n",
       "\n",
       "                                                  3   \\\n",
       "0  {'year': '15', 'yearUnparsed': 'DocEng '15', '...   \n",
       "\n",
       "                                                  4   \\\n",
       "0  {'year': '14', 'yearUnparsed': 'DocEng '14', '...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  {'year': '13', 'yearUnparsed': 'DocEng '13', '...   \n",
       "\n",
       "                                                  6   \\\n",
       "0  {'year': '12', 'yearUnparsed': 'DocEng '12', '...   \n",
       "\n",
       "                                                  7   \\\n",
       "0  {'year': '11', 'yearUnparsed': 'DocEng '11', '...   \n",
       "\n",
       "                                                  8   \\\n",
       "0  {'year': '10', 'yearUnparsed': 'DocEng '10', '...   \n",
       "\n",
       "                                                  9   \\\n",
       "0  {'year': '09', 'yearUnparsed': 'DocEng '09', '...   \n",
       "\n",
       "                                                  10  \\\n",
       "0  {'year': '08', 'yearUnparsed': 'DocEng '08', '...   \n",
       "\n",
       "                                                  11  \\\n",
       "0  {'year': '07', 'yearUnparsed': 'DocEng '07', '...   \n",
       "\n",
       "                                                  12  \\\n",
       "0  {'year': '06', 'yearUnparsed': 'DocEng '06', '...   \n",
       "\n",
       "                                                  13  \\\n",
       "0  {'year': '05', 'yearUnparsed': 'DocEng '05', '...   \n",
       "\n",
       "                                                  14  \\\n",
       "0  {'year': '04', 'yearUnparsed': 'DocEng '04', '...   \n",
       "\n",
       "                                                  15  \\\n",
       "0  {'year': '03', 'yearUnparsed': 'DocEng '03', '...   \n",
       "\n",
       "                                                  16  \\\n",
       "0  {'year': '02', 'yearUnparsed': 'DocEng '02', '...   \n",
       "\n",
       "                                                  17  \n",
       "0  {'year': '01', 'yearUnparsed': 'DocEng '01', '...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_level = pd.json_normalize(df_AcmConferences_raw.iloc[[0]]['info'])\n",
    "df_first_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>yearUnparsed</th>\n",
       "      <th>yearUrl</th>\n",
       "      <th>submitted</th>\n",
       "      <th>accepted</th>\n",
       "      <th>percAccepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>DocEng '19</td>\n",
       "      <td>https://dl.acm.org/doi/proceedings/10.1145/334...</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "      <td>39%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  year yearUnparsed                                            yearUrl  \\\n",
       "0   19   DocEng '19  https://dl.acm.org/doi/proceedings/10.1145/334...   \n",
       "\n",
       "  submitted accepted percAccepted  \n",
       "0        77       30          39%  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(df_first_level.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of the JSON Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the JSON Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the processing function (is going to be used for all the different datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_dataframe(raw_dataframe):\n",
    "    out_row_list = list()\n",
    "\n",
    "    for index, row in raw_dataframe.iterrows():\n",
    "\n",
    "        # expansion from the info field\n",
    "        df_first_level = pd.json_normalize(row['info'])\n",
    "\n",
    "        for index_first_level, row_first_level in df_first_level.iterrows():\n",
    "            # check if there's the year\n",
    "            try:\n",
    "                row_first_level['year'] \n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            # check if there's the percAccepted\n",
    "            try:\n",
    "                row_first_level['percAccepted'] \n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            # filter of null rows\n",
    "            if pd.isnull(row_first_level['year']) or pd.isnull(row_first_level['percAccepted']) or pd.isnull(row_first_level['submitted']) or pd.isnull(row_first_level['accepted']):\n",
    "                continue # skip row\n",
    "\n",
    "            # filter of some year special cases\n",
    "            if isinstance(row_first_level['year'], str):\n",
    "                if row_first_level['year'].__len__() > 4: # special case like \"19 Companion\", that we need to filter\n",
    "                    continue # skip row\n",
    "\n",
    "            # filter of some invalid data\n",
    "            if \"?\" in str(row_first_level['submitted']) or \"?\" in str(row_first_level['accepted']) or \"?\" in str(row_first_level['percAccepted']):\n",
    "                continue # skip row\n",
    "\n",
    "            # normalization of the year format\n",
    "            year = int(row_first_level['year'])\n",
    "            if year < 100: # two figures\n",
    "                year = 2000 + year\n",
    "\n",
    "            # creation of the support dataframe\n",
    "            support_dict = dict()\n",
    "            support_dict['Conf_Acronym'] = row['confAcronym'].lower()\n",
    "            support_dict['Year'] = year\n",
    "\n",
    "            # removing points or commas \n",
    "            submitted_str = str(row_first_level['submitted']).split(\".\")[0].split(\",\")[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].split(\"(\")[0]\n",
    "            if \"~\" in submitted_str:\n",
    "                submitted_str = submitted_str.split(\"~\")[1]\n",
    "            submitted_str = submitted_str.strip()\n",
    "            if submitted_str.__len__() == 0 or \"--\" in submitted_str or not submitted_str.isnumeric():\n",
    "                continue # skip row\n",
    "            submitted = int(submitted_str)\n",
    "\n",
    "            accepted_str = str(row_first_level['accepted']).split(\".\")[0].split(\",\")[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].split(\"(\")[0]\n",
    "            if \":\" in accepted_str:\n",
    "                accepted_str = accepted_str.split(\":\")[1]\n",
    "            if \"~\" in accepted_str:\n",
    "                accepted_str = accepted_str.split(\"~\")[1]\n",
    "            accepted_str = accepted_str.strip()\n",
    "            if accepted_str.__len__() == 0 or \"--\" in accepted_str or not accepted_str.isnumeric():\n",
    "                continue # skip row\n",
    "            accepted = int(accepted_str)\n",
    "                \n",
    "\n",
    "            perc_accepted_str = str(row_first_level['percAccepted']).split('%')[0].split(\"+\")[0].split(\">\")[0].split(\"<\")[0].replace(\",\", \".\")\n",
    "            if perc_accepted_str.__len__() == 0:\n",
    "                continue # skip row\n",
    "            if \"~\" in perc_accepted_str:\n",
    "                perc_accepted = float(perc_accepted_str.split(\"~\")[1])\n",
    "            else:\n",
    "                perc_accepted = float(perc_accepted_str)\n",
    "\n",
    "            support_dict['Papers_Submitted'] = submitted\n",
    "            support_dict['Papers_Accepted'] = accepted\n",
    "            support_dict['Papers_Perc_Accepted'] = perc_accepted\n",
    "            \n",
    "            # putting the values inside our output list\n",
    "            out_row_list.append(support_dict)\n",
    "\n",
    "    # conversion of the output list to a dataframe\n",
    "    return pd.DataFrame(out_row_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Reading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing JSON: CryptographyConferencesStatistics.json\n",
      "Currently processing JSON: TheoreticalCSConferencesStatistics.json\n",
      "Currently processing JSON: NetworkingConferencesStatistics.json\n",
      "Currently processing JSON: AcmConferences.json\n",
      "Currently processing JSON: SEConferencesStatistics.json\n",
      "Currently processing JSON: ComputerSecurityConferencesStatistics.json\n"
     ]
    }
   ],
   "source": [
    "output_dataframes_list = list()\n",
    "\n",
    "poggis_all_jsons = glob.glob(path_file_import + \"*.json\")\n",
    "\n",
    "for current_json_name_full in poggis_all_jsons:\n",
    "\n",
    "    current_json_name = current_json_name_full.split(\"/\")[-1]\n",
    "\n",
    "    # Open the current CSV\n",
    "    print(f'Currently processing JSON: {current_json_name}')\n",
    "    df_current_json = pd.read_json(current_json_name_full)\n",
    "\n",
    "    # Processing of the json file\n",
    "    output_dataframes_list.append(process_json_dataframe(df_current_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the first processed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Conf_Acronym  Year  Papers_Submitted  Papers_Accepted  \\\n",
      "0         crypto  2014               227               60   \n",
      "1         crypto  2013               227               61   \n",
      "2         crypto  2012               225               48   \n",
      "3         crypto  2011               230               42   \n",
      "4         crypto  2010               202               39   \n",
      "..           ...   ...               ...              ...   \n",
      "122          tcc  2010               100               33   \n",
      "123          tcc  2009               109               33   \n",
      "124          tcc  2008                81               33   \n",
      "125          tcc  2007               118               31   \n",
      "126          tcc  2006                91               31   \n",
      "\n",
      "     Papers_Perc_Accepted  \n",
      "0                    26.4  \n",
      "1                    26.9  \n",
      "2                    21.3  \n",
      "3                    18.3  \n",
      "4                    19.3  \n",
      "..                    ...  \n",
      "122                  33.0  \n",
      "123                  30.3  \n",
      "124                  40.7  \n",
      "125                  26.3  \n",
      "126                  34.1  \n",
      "\n",
      "[127 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "if output_dataframes_list.__len__() > 0:\n",
    "    print(output_dataframes_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Between the Different Processed JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write of the Final CSVs on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the resulting dataframe on disk in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Exported the Joined CSV to /Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/out_conference_series_with_core_rank.csv\n"
     ]
    }
   ],
   "source": [
    "# Write of the resulting CSVs on Disk\n",
    "df_conference_series_with_core_rank.to_csv(path_file_export + 'out_conference_series_with_core_rank.csv')\n",
    "print(f'Successfully Exported the Joined CSV to {path_file_export}out_conference_series_with_core_rank.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the Exported CSV to be sure that everything went fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORE_2008_Rank</th>\n",
       "      <th>CORE_2013_Rank</th>\n",
       "      <th>CORE_2014_Rank</th>\n",
       "      <th>CORE_2017_Rank</th>\n",
       "      <th>CORE_2018_Rank</th>\n",
       "      <th>CORE_2020_Rank</th>\n",
       "      <th>CORE_2021_Rank</th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "      <th>ERA_2010_Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>disc</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>esa</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>enter</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>dexa</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>icaisc</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>infinity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>calculemus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>agp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sci</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sapere</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5312 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CORE_2008_Rank CORE_2013_Rank CORE_2014_Rank CORE_2017_Rank  \\\n",
       "0                 A              A              A              A   \n",
       "1                 A              A              A              A   \n",
       "2               NaN              C              C              C   \n",
       "3                 A              B              B              B   \n",
       "4               NaN              C              C              C   \n",
       "...             ...            ...            ...            ...   \n",
       "5307            NaN            NaN            NaN            NaN   \n",
       "5308            NaN            NaN            NaN            NaN   \n",
       "5309            NaN            NaN            NaN            NaN   \n",
       "5310            NaN            NaN            NaN            NaN   \n",
       "5311            NaN            NaN            NaN            NaN   \n",
       "\n",
       "     CORE_2018_Rank CORE_2020_Rank CORE_2021_Rank  \\\n",
       "0                 A              A              A   \n",
       "1                 A              A              A   \n",
       "2                 C              C              C   \n",
       "3                 B              B              B   \n",
       "4                 C            NaN            NaN   \n",
       "...             ...            ...            ...   \n",
       "5307            NaN            NaN            NaN   \n",
       "5308            NaN            NaN            NaN   \n",
       "5309            NaN            NaN            NaN   \n",
       "5310            NaN            NaN            NaN   \n",
       "5311            NaN            NaN            NaN   \n",
       "\n",
       "     ConferenceSeriesNormalizedName ERA_2010_Rank  \n",
       "0                              disc             A  \n",
       "1                               esa             A  \n",
       "2                             enter             C  \n",
       "3                              dexa             B  \n",
       "4                            icaisc             C  \n",
       "...                             ...           ...  \n",
       "5307                       infinity           NaN  \n",
       "5308                     calculemus           NaN  \n",
       "5309                            agp           NaN  \n",
       "5310                            sci           NaN  \n",
       "5311                         sapere           NaN  \n",
       "\n",
       "[5312 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check of the Exported CSV\n",
    "df_conference_series_with_core_rank = pd.read_csv(path_file_export + 'out_conference_series_with_core_rank.csv', low_memory=False, index_col=[0])\n",
    "df_conference_series_with_core_rank"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
