{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation and Conference Data Cleanup and Normalization\n",
    "\n",
    "Jupyter Notebook for the cleanup and normalization of the conferences locations of the joined datasets.\n",
    "\n",
    "Microsoft Academics Graph and DBLP use two different scheme of rapresentation for the locations.\n",
    "\n",
    "For example, some locations are represented in the following format *City, State*, while while others in the *City, State, USA* format.<br>\n",
    "Also, there are Locations that wrongly contains their Conference Name that needs to be filtered, or dates, or touristic locations, and so on.<br>\n",
    "\n",
    "These different formats create ambiguity that we need to solve.\n",
    "____________________________________________________________\n",
    "\n",
    "For this process, the following CSV files are needed: ```out_citations_and_conferences.csv``` and ```out_citations_by_year_and_conferences.csv```. <br>\n",
    "The first one must be generated running the Notebook ```2 - DBLP+MAG and COCI Data Join.ipynb``` that is contained in the ```3 - Citation and Conference Data Join``` folder of this project.<br>\n",
    "The second one must be generated running the Notebook ```3 - DBLP + MAG Join with COCI RAW for By Year Citations.ipynb``` that is contained in the ```3 - Citation and Conference Data Join``` folder of this project.\n",
    "\n",
    "In particular, the following operations are going to be executed:\n",
    "* Opening of the CSV joined datasets\n",
    "* Drop of the useless columns\n",
    "* Manual Filter and Disambiguation of the main cases\n",
    "* Removal of the conference name\n",
    "* Location Sanitization and Normalization Using GeoPy\n",
    "* Drop of the Location that only have the state (but not the city)\n",
    "\n",
    "Lastly, the processed datasets are going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n",
    "Please set your working directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Import/COCI_RAW/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read of the Joined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Imported the Conference Citations and Locations CSV\n",
      "Successfully Imported the Conference Citations by Year and Locations CSV\n"
     ]
    }
   ],
   "source": [
    "df_citations_and_locations = pd.read_csv(path_file_export + 'out_citations_and_conferences.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the Conference Citations and Locations CSV')\n",
    "\n",
    "df_citations_by_year_and_locations = pd.read_csv(path_file_export + 'out_citations_by_year_and_conferences.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the Conference Citations by Year and Locations CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Citations and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitationCount_COCI</th>\n",
       "      <th>CitationCount_Mag</th>\n",
       "      <th>CitationCount_MagEstimated</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceTitle</th>\n",
       "      <th>Doi</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>Distributed Computing - 28th International Sym...</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>Algorithms - ESA 2014 - 22th Annual European S...</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>Information and Communication Technologies in ...</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>SoCoMo Marketing for Travel and Tourism</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitationCount_COCI  CitationCount_Mag  CitationCount_MagEstimated  \\\n",
       "0                  10                 12                          12   \n",
       "1                   5                 10                          10   \n",
       "2                  11                 20                          20   \n",
       "\n",
       "   ConferenceLocation ConferenceNormalizedName  \\\n",
       "0          Austin, TX                disc 2014   \n",
       "1     Wrocław, Poland                 esa 2014   \n",
       "2  Innsbruck, Austria               enter 2013   \n",
       "\n",
       "                                     ConferenceTitle  \\\n",
       "0  Distributed Computing - 28th International Sym...   \n",
       "1  Algorithms - ESA 2014 - 22th Annual European S...   \n",
       "2  Information and Communication Technologies in ...   \n",
       "\n",
       "                            Doi  \\\n",
       "0  10.1007/978-3-662-45174-8_28   \n",
       "1  10.1007/978-3-662-44777-2_60   \n",
       "2  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "                                       OriginalTitle  Year  \n",
       "0  The Adaptive Priority Queue with Elimination a...  2014  \n",
       "1       Document Retrieval on Repetitive Collections  2014  \n",
       "2            SoCoMo Marketing for Travel and Tourism  2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Citations by Year and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceTitle</th>\n",
       "      <th>Doi</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>Distributed Computing - 28th International Sym...</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>Algorithms - ESA 2014 - 22th Annual European S...</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>Information and Communication Technologies in ...</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>SoCoMo Marketing for Travel and Tourism</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConferenceLocation ConferenceNormalizedName  \\\n",
       "0          Austin, TX                disc 2014   \n",
       "1     Wrocław, Poland                 esa 2014   \n",
       "2  Innsbruck, Austria               enter 2013   \n",
       "\n",
       "                                     ConferenceTitle  \\\n",
       "0  Distributed Computing - 28th International Sym...   \n",
       "1  Algorithms - ESA 2014 - 22th Annual European S...   \n",
       "2  Information and Communication Technologies in ...   \n",
       "\n",
       "                            Doi  \\\n",
       "0  10.1007/978-3-662-45174-8_28   \n",
       "1  10.1007/978-3-662-44777-2_60   \n",
       "2  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "                                       OriginalTitle  Year  1950  1951  1952  \\\n",
       "0  The Adaptive Priority Queue with Elimination a...  2014     0     0     0   \n",
       "1       Document Retrieval on Repetitive Collections  2014     0     0     0   \n",
       "2            SoCoMo Marketing for Travel and Tourism  2013     0     0     0   \n",
       "\n",
       "   1953  1954  1955  1956  1957  1958  1959  1960  1961  1962  1963  1964  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1965  1966  1967  1968  1969  1970  1971  1972  1973  1974  1975  1976  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1977  1978  1979  1980  1981  1982  1983  1984  1985  1986  1987  1988  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1989  1990  1991  1992  1993  1994  1995  1996  1997  1998  1999  2000  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2001  2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  2012  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2013  2014  2015  2016  2017  2018  2019  2020  2021  2022  \n",
       "0     0     0     2     1     1     0     2     1     2     0  \n",
       "1     0     0     2     0     2     0     0     0     0     0  \n",
       "2     0     3     0     3     2     0     1     1     0     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_by_year_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop of the Useless Columns\n",
    "First of all, we're going to drop the columns that are not needed anymore.<br>\n",
    "The following columns are going to be removed:\n",
    "* ConferenceTitle: the full title of the conference. It's not defined for a lot a conferences.\n",
    "* OriginalTitle: the paper's title. It's not defined for the most of the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations.drop(columns=['ConferenceTitle', 'OriginalTitle'], inplace=True)\n",
    "df_citations_by_year_and_locations.drop(columns=['ConferenceTitle', 'OriginalTitle'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitationCount_COCI</th>\n",
       "      <th>CitationCount_Mag</th>\n",
       "      <th>CitationCount_MagEstimated</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitationCount_COCI  CitationCount_Mag  CitationCount_MagEstimated  \\\n",
       "0                  10                 12                          12   \n",
       "1                   5                 10                          10   \n",
       "2                  11                 20                          20   \n",
       "\n",
       "   ConferenceLocation ConferenceNormalizedName                           Doi  \\\n",
       "0          Austin, TX                disc 2014  10.1007/978-3-662-45174-8_28   \n",
       "1     Wrocław, Poland                 esa 2014  10.1007/978-3-662-44777-2_60   \n",
       "2  Innsbruck, Austria               enter 2013  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "   Year  \n",
       "0  2014  \n",
       "1  2014  \n",
       "2  2013  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConferenceLocation ConferenceNormalizedName                           Doi  \\\n",
       "0          Austin, TX                disc 2014  10.1007/978-3-662-45174-8_28   \n",
       "1     Wrocław, Poland                 esa 2014  10.1007/978-3-662-44777-2_60   \n",
       "2  Innsbruck, Austria               enter 2013  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "   Year  1950  1951  1952  1953  1954  1955  1956  1957  1958  1959  1960  \\\n",
       "0  2014     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1  2014     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2  2013     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  1971  1972  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1973  1974  1975  1976  1977  1978  1979  1980  1981  1982  1983  1984  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1985  1986  1987  1988  1989  1990  1991  1992  1993  1994  1995  1996  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1997  1998  1999  2000  2001  2002  2003  2004  2005  2006  2007  2008  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2009  2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  \\\n",
       "0     0     0     0     0     0     0     2     1     1     0     2     1   \n",
       "1     0     0     0     0     0     0     2     0     2     0     0     0   \n",
       "2     0     0     0     0     0     3     0     3     2     0     1     1   \n",
       "\n",
       "   2021  2022  \n",
       "0     2     0  \n",
       "1     0     0  \n",
       "2     0     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_by_year_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conference Location Manual Cleanup\n",
    "Before submitting the location data to an automatic location recognizer, I decided to manually cleanup and filter the most of the issues I found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to filter the papers that do not have a location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation filtered about 1.5M of rows\n"
     ]
    }
   ],
   "source": [
    "original_rows = df_citations_and_locations.index.__len__()\n",
    "\n",
    "df_citations_and_locations = df_citations_and_locations[df_citations_and_locations['ConferenceLocation'].notna()]\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations[df_citations_by_year_and_locations['ConferenceLocation'].notna()]\n",
    "\n",
    "actual_rows = df_citations_and_locations.index.__len__()\n",
    "\n",
    "print(f\"The operation filtered about {round(((original_rows - actual_rows) / 1000000), 1)}M of rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the Distinct Conferences Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to extract the distinct conferences locations:<br>\n",
    "**Note**: since the two dataframes contain exactly the same papers and locations, the following operations are going to be executed only on a dataframe, and then replicated on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = df_citations_and_locations.drop_duplicates(subset=\"ConferenceLocation\")['ConferenceLocation'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the locations that only have the state (but don't have the city): the don't need to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_locations_list = list()\n",
    "\n",
    "for loc in locations_list:\n",
    "    if loc.split(',').__len__() >= 2:\n",
    "        new_locations_list.append(loc)\n",
    "\n",
    "locations_list = new_locations_list\n",
    "new_locations_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a Support Dictionary\n",
    "We're going to create a support dictionary that's going to contain the locations and their fixed name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict = dict()\n",
    "\n",
    "for loc in locations_list:\n",
    "    locations_fix_dict[loc] = loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix of the Locations in the Format \"City,state_acronym\"\n",
    "Some locations are in the format \"City,state_acronym\". We need to convert them to \"City, STATE_ACRONYM\".\n",
    "\n",
    "For example: \"Hamilton,nz\" to \"Hamilton, NZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    if locations_fix_dict[loc].split(',').__len__() == 2 and locations_fix_dict[loc].split(',')[1].__len__() == 2:\n",
    "        locations_fix_dict[loc] = str(locations_fix_dict[loc].split(',')[0] + ', ' + locations_fix_dict[loc].split(',')[1].upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix of Some Extra Spacings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(' ,', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of the \"- United State of America\" and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\" - United States of America\", \"\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\" - United States\", \"\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\" - United Kingdom of Great Britain and Northern Ireland\", \"\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"Netherlands - Kingdom of the Netherlands\", \"The Netherlands\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"The Netherlands - Including\", \"The Netherlands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US, USA, U.S.A., U.S. and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"United States\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"USA\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S.A.\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S.A\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"USA.\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S.\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"US\", \"USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### United Kingdom, Great Bretain, and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"GB\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"United Kingdom\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"England\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.K.\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.K\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"G.B.\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"G.B\", \"UK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### South Korea and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"S.Korea\", \"Korea (South)\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"S. Korea\", \"Korea (South)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"(near Place)\" Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some places are in the following format: \"place_name (near big_town_name), [...]\"\n",
    "\n",
    "We need to convert them in the following format: \"big_town_name, [...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    if \" (near \" in locations_fix_dict[loc]:\n",
    "        locations_fix_dict[loc] = locations_fix_dict[loc].split(\" (near \")[1].split(\")\")[0] + locations_fix_dict[loc].split(\" (near \")[1].split(\")\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"near Place\" Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some places are in the following format: \"place_name near big_town_name, [...]\"\n",
    "\n",
    "We need to convert them in the following format: \"big_town_name, [...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    if \" near \" in locations_fix_dict[loc]:\n",
    "        locations_fix_dict[loc] = locations_fix_dict[loc].split(\" near \")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the Conference Name\n",
    "There are a small number of cases where the location wrongly contains the conference name. We need to filter it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try to filter some cases automatically.\n",
    "\n",
    "In fact, in the most of the cases we have two formats:\n",
    "* \"CONF_NAME YEAR, Location\"\n",
    "* \"CONF_NAME'YEAR, Location\"\n",
    "* \"CONF_NAME-YEAR, Location\"\n",
    "* \"CONF_NAME, Location\": we'll address this case manually, since they are difficult to be distinguished from the normal locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "\n",
    "    count = 0\n",
    "    loc_splitted_list = locations_fix_dict[loc].split(',')\n",
    "    needs_to_be_fixed = False\n",
    "\n",
    "    if loc_splitted_list.__len__() >= 2:\n",
    "\n",
    "        # Here we check the \"CONF_NAME YEAR, Location\" format\n",
    "        if loc_splitted_list[0].split(' ').__len__() == 2 and loc_splitted_list[0].split(' ')[1].isnumeric():\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        # Here we check the \"CONF_NAME'YEAR, Location\" format\n",
    "        if loc_splitted_list[0].split(\"'\").__len__() == 2 and loc_splitted_list[0].split(\"'\")[1].isnumeric():\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        # Here we check the \"CONF_NAME-YEAR, Location\" format\n",
    "        if loc_splitted_list[0].split('-').__len__() == 2 and loc_splitted_list[0].split('-')[1].isnumeric():\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if needs_to_be_fixed:\n",
    "            locations_fix_dict[loc] = \"\"\n",
    "\n",
    "            for el in loc_splitted_list:\n",
    "                if count == 0:\n",
    "                    pass # the first element is the conference name\n",
    "                else:\n",
    "                    if str(el)[0] == ' ':\n",
    "                        el = str(el)[1:] # Filtering the blank space\n",
    "                        \n",
    "                    if count == 1: # the first doesn't need the comma\n",
    "                        locations_fix_dict[loc] += el\n",
    "                    else:\n",
    "                        locations_fix_dict[loc] += ', ' + el\n",
    "                \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addressing other special conferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "\n",
    "    count = 0\n",
    "    loc_splitted_list = locations_fix_dict[loc].split(',')\n",
    "    needs_to_be_fixed = False\n",
    "\n",
    "    if loc_splitted_list.__len__() >= 2:\n",
    "\n",
    "        if \"ASIC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"COIN@AAMAS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"EvoFIN, EvoSTOC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IEEE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"EvoSTOC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IIT\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"VLSI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"EvoFIN\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IST\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IMC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DEXA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CAMS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ACM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SC11\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SCIDOCA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CBD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"TBD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WAIM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"KAIST\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CompSysTech\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ESupercomputing\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"HEC2016\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"BIRTE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IWANN2003\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Web3D\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WoTUG\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"XSEDE13\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DBISP2P\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Erlang\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CNAM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"PX/16\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SESoS@ECOOP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WISE9\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CDT&SECOMANE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Reengineering\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Multimedia\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Mobile\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WBICV\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DCSA, DC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"FHPCN\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WISA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"P^3MA, WOPSSS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WOPSSS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"HardBD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MoDeVVa\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"QLD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"FedCSIS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ReConFig14\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WGLBWS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ETAPS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SoMeT_17\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"PARLE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Banff\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Informatics\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"NLP&DBpedia\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SIGGRAPH\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DNA8\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SGAI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DCNET\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Meta4eS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ARRAY@PLDI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ALSIP, SocNet, BigPMA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ITiCSE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Supercomputersystemen\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ITEE2013\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CSP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Algorithmics\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"China\" in loc_splitted_list[0]: # not a conference, but threated in the same way\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"UK\" in loc_splitted_list[0]: # not a conference, but threated in the same way\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"BigNovelTI, SW4CH\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SW4CH\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"M2P\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Society\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IoTPTS@AsiaCCS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"PPREW@ACSAC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Eurasia\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DUI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Parallel\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Education\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Humanity\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"NLP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MSA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Modeling\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MoDIC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WM2SP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"QoIS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ETheCoM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"XSDM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Virtual Event\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Workshops\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"1992\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SMAP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MaLTeSQuE@SANER\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Mobile\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"TRNC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"the UK & Ireland Computing Education Research Conference\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WBDB.cn\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"QUOVADIS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ULSSIS@ICSE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Training\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ICoC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if needs_to_be_fixed:\n",
    "            locations_fix_dict[loc] = \"\"\n",
    "\n",
    "            for el in loc_splitted_list:\n",
    "                if count == 0:\n",
    "                    pass # the first element is the conference name\n",
    "                else:\n",
    "                    if str(el)[0] == ' ':\n",
    "                        el = str(el)[1:] # Filtering the blank space\n",
    "                        \n",
    "                    if count == 1: # the first doesn't need the comma\n",
    "                        locations_fix_dict[loc] += el\n",
    "                    else:\n",
    "                        locations_fix_dict[loc] += ', ' + el\n",
    "                \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"Virtual Event / \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict[\"York, UK / 2nd AAMAS 2002\"] = \"York, UK\"\n",
    "locations_fix_dict[\"Eugene, OR, USA / 2nd IWOMP 2006\"] = \"Eugene, OR, USA\"\n",
    "locations_fix_dict[\"Ausbildung, INFOS'95, Chemnitz\"] = \"Ausbildung, Chemnitz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "\n",
    "    count = 0\n",
    "    loc_splitted_list = locations_fix_dict[loc].split(',')\n",
    "    needs_to_be_fixed = False\n",
    "\n",
    "    if loc_splitted_list.__len__() >= 2:\n",
    "\n",
    "        if \"University of \" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if \" University\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if needs_to_be_fixed:\n",
    "            locations_fix_dict[loc] = loc_splitted_list[0].replace(\"University of \", \"\")\n",
    "            locations_fix_dict[loc] = loc_splitted_list[0].replace(\" University\", \"\")\n",
    "\n",
    "            for el in loc_splitted_list:\n",
    "                if count >= 1:\n",
    "                    if str(el)[0] == ' ':\n",
    "                        el = str(el)[1:] # Filtering the blank space\n",
    "                        \n",
    "                        locations_fix_dict[loc] += ', ' + el\n",
    "                \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Fix of the Special Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cases here are of various kind. We can have some mismatched caracter cases, or wrong spacings, or the indication of the place of the conference (such as hotels, etc).\n",
    "\n",
    "These cases need to be addressed one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict[\"Lyon,\\xa0France\"] = \"Lyon, France\"\n",
    "locations_fix_dict[\", USA\"] = \"USA\"\n",
    "locations_fix_dict[\"CANCUN, Mexico\"] = \"Cancun, Mexico\"\n",
    "locations_fix_dict[\"Auckland, New Zealand, 8-12 August 2016\"] = \"Auckland, New Zealand\"\n",
    "locations_fix_dict[\"IOWA STATE UNIVERSITY, USA\"] = \"Iowa, USA\"\n",
    "locations_fix_dict[\"No.1, Dai Co Viet Rd, Hanoi, Vietnam\"] = \"Hanoi, Vietnam\"\n",
    "locations_fix_dict[\"Guilin,Guangxi, China\"] = \"Guilin, Guangxi, China\"\n",
    "locations_fix_dict[\"Gyeongju, Republic of Korea - March\"] = \"Gyeongju, Republic of Korea\"\n",
    "locations_fix_dict[\"Harbin,China\"] = \"Harbin, China\"\n",
    "locations_fix_dict[\"Washington, D. C., USA\"] = \"Washington D.C., USA\"\n",
    "locations_fix_dict[\"Funchal, Madeira - Portugal\"] = \"Funchal, Madeira, Portugal\"\n",
    "locations_fix_dict[\"Kuantan, Pahang, MALAYSIA\"] = \"Kuantan, Pahang, Malaysia\"\n",
    "locations_fix_dict[\"Phoenix Park, PyeongChang,, Korea (South)\"] = \"Phoenix Park, PyeongChang, Korea (South)\"\n",
    "locations_fix_dict[\"EvoFIN, EvoSTOC, Germany\"] = \"Germany\"\n",
    "locations_fix_dict[\"Prague,\"] = \"Prague\"\n",
    "locations_fix_dict[\", York, UK\"] = \"York, UK\"\n",
    "locations_fix_dict[\"Royal Continental Hotel,Naples, Italy\"] = \"Naples, Italy\"\n",
    "locations_fix_dict[\"Puebla, MEXICO\"] = \"Puebla, Mexico\"\n",
    "locations_fix_dict[\"Jun 16-20, 2008\"] = \"\"\n",
    "locations_fix_dict[\"Taipei, Taiwan, August 29-31, 2012.\"] = \"Taipei, Taiwan\"\n",
    "locations_fix_dict[\"YORK, UK\"] = \"York, UK\"\n",
    "locations_fix_dict[\"Kuala Lumpur, Malaysia.\"] = \"Kuala Lumpur, Malaysia\"\n",
    "locations_fix_dict[\"Brisbane Convention & Exhibition Centre, Brisbane, Australia\"] = \"Brisbane, Australia\"\n",
    "locations_fix_dict[\"Vienna University of Technology, Vienna\"] = \"Vienna, Austria\"\n",
    "locations_fix_dict[\"Hammamet,Tunisia\"] = \"Hammamet, Tunisia\"\n",
    "locations_fix_dict[\"MIT, Cambridge, USA\"] = \"Cambridge, USA\"\n",
    "locations_fix_dict[\"Cumbria, United, Kngdm\"] = \"Cumbria, UK\"\n",
    "locations_fix_dict[\"Hilton Hotel Cyprus, Nicosia\"] = \"Cyprus, Nicosia\"\n",
    "locations_fix_dict[\"changsha, China\"] = \"Changsha, China\"\n",
    "locations_fix_dict[\"Durham, NC USA\"] = \"Durham, NC, USA\"\n",
    "locations_fix_dict[\"International, Mykonos Island, Greece\"] = \"Mykonos Island, Greece\"\n",
    "locations_fix_dict[\"GUNTUR, Vijayawada, PIN 622510,in\"] = \"Vijayawada, IN\"\n",
    "locations_fix_dict[\"Bolzano-Bozen, Italy\"] = \"Bolzen, Italy\"\n",
    "locations_fix_dict[\"Providence, RI,\"] = \"Providence, RI\"\n",
    "locations_fix_dict[\"Adisaptagram, Hooghly - 712121, India\"] = \"Adisaptagram, Hooghly, India\"\n",
    "locations_fix_dict[\"Alexandria, Virginia, U.S.\"] = \"Alexandria, Virginia, USA\"\n",
    "locations_fix_dict[\"guilin, china\"] = \"Guilin, China\"\n",
    "locations_fix_dict[\"Washington, D.C. (USA)\"] = \"Washington D.C., USA\"\n",
    "locations_fix_dict[\"San, Diego, CA, USA\"] = \"San Diego, CA, USA\"\n",
    "locations_fix_dict[\"Kinsdale,\"] = \"Kinsdale\"\n",
    "locations_fix_dict[\"Bhubaneswar,India.\"] = \"Bhubaneswar, India\"\n",
    "locations_fix_dict[\"Beijing, People's Republic of China\"] = \"Beijing, China\"\n",
    "locations_fix_dict[\"DARMSTADT, Germany.\"] = \"Darmstadt, Germany\"\n",
    "locations_fix_dict[\"singapore, Singapore\"] = \"Singapore, Singapore\"\n",
    "locations_fix_dict[\"St.-Petersburg, Russia\"] = \"St. Petersburg, Russia\"\n",
    "locations_fix_dict[\"Suwon, Korea,\"] = \"Suwon, Korea\"\n",
    "locations_fix_dict[\"Curium Palace Hotel, Limassol, Cyprus\"] = \"Limassol, Cyprus\"\n",
    "locations_fix_dict[\"Vilanova i la Geltru, Barcelona, Spain\"] = \"Barcelona, Spain\"\n",
    "locations_fix_dict[\"Vancouver Convention Center, Vancouver CANADA \"] = \"Vancouver, Canada\"\n",
    "locations_fix_dict[\"Chiang Mai,, Thailand\"] = \"Chiang Mai, Thailand\"\n",
    "locations_fix_dict[\"DIVANI PALACE ACROPOLIS Athens, Greece\"] = \"Athens, Greece\"\n",
    "locations_fix_dict[\"Greenwich, London (UK)\"] = \"London, UK\"\n",
    "locations_fix_dict[\"Madrid,Spain\"] = \"Madrid, Spain\"\n",
    "locations_fix_dict[\"Chongqing,China\"] = \"Chongqing, China\"\n",
    "locations_fix_dict[\"Training, Atlanta, GA, USA\"] = \"Atlanta, GA, USA\"\n",
    "locations_fix_dict[\"denver, CA, USA\"] = \"Denver, CA, USA\"\n",
    "locations_fix_dict[\"HANGZHOU, PEOPLE'S REPUBLIC OF CHINA\"] = \"Hangzhou, China\"\n",
    "locations_fix_dict[\"Portland, Oregon, June 18-19, 2015\"] = \"Portland, Oregon\"\n",
    "locations_fix_dict[\"UK, Guildford, United Kingdom\"] = \"Guildford, UK\"\n",
    "locations_fix_dict[\"London (Guildford), United Kingdom\"] = \"London, UK\"\n",
    "locations_fix_dict[\"MIT, Cambridge, U.S.A\"] = \"Cambridge, USA\"\n",
    "locations_fix_dict[\"54 on Bath, Rosebank, Johannesburg, South Africa\"] = \"Rosebank, Johannesburg, South Africa\"\n",
    "locations_fix_dict[\"hONOLULU, hAWAII\"] = \"Honolulu, Hawaii\"\n",
    "locations_fix_dict[\"Hefei, P.R.China\"] = \"Hefei, China\"\n",
    "locations_fix_dict[\"National Ilan Unviersity, I-Lan, Taiwan\"] = \"I-Lan, Taiwan\"\n",
    "locations_fix_dict[\"Galt House Hotel, Louisville, Kentucky, USA - United States\"] = \"Kentucky, USA - United States\"\n",
    "locations_fix_dict[\"HIROSHIMA, JAPAN\"] = \"Hiroshima, Japan\"\n",
    "locations_fix_dict[\"UK, Bradford, UK\"] = \"Bradford, UK\"\n",
    "locations_fix_dict[\"ETH Zürich, Zurich, Switzerland\"] = \"Zurich, Switzerland\"\n",
    "locations_fix_dict[\"THE FAIRMONT, SAN JOSE, CA\"] = \"San Jose, CA\"\n",
    "locations_fix_dict[\"Shenzhen, China (collocated with HPCA)\"] = \"Shenzhen, China\"\n",
    "locations_fix_dict[\"Birmingham City Univ, UK\"] = \"Birmingham, UK\"\n",
    "locations_fix_dict[\"Dublin City, Univ., Ireland\"] = \"Dublin, Ireland\"\n",
    "locations_fix_dict[\"Saint John's, Newfoundland and Labrador,\"] = \"\"\n",
    "locations_fix_dict[\"ANNECY, FRANCE - IMPERIAL PALACE\"] = \"Annecy, France\"\n",
    "locations_fix_dict[\"Nanyang Technological University, Singapore\"] = \"Nanyang, Singapore\"\n",
    "locations_fix_dict[\"San Francisco Bay Area, USA\"] = \"San Francisco, USA\"\n",
    "locations_fix_dict[\"TU Berlin, Berlin, Germany\"] = \"Berlin, Germany\"\n",
    "locations_fix_dict[\"Grecian Bay Hotel, Ayia Napa, Cyprus\"] = \"Ayia Napa, Cyprus\"\n",
    "locations_fix_dict[\"Aristi Village, Zagorochoria, Greece\"] = \"Zagorochoria, Greece\"\n",
    "locations_fix_dict[\"KENITRA, MA\"] = \"Kinitra, MA\"\n",
    "locations_fix_dict[\"Exeter College, Oxford, UK - UK\"] = \"Exeter College, Oxford, UK\"\n",
    "locations_fix_dict[\"2008\"] = \"\"\n",
    "locations_fix_dict[\"UK, Edinburgh, UK\"] = \"Edinburgh, UK\"\n",
    "locations_fix_dict[\"Bhubaneswar,Odisha, India\"] = \"Bhubaneswar, Odisha, India\"\n",
    "locations_fix_dict[\"Hyatt Harborside, Boston, Massachusetts, USA\"] = \"Boston, Massachusetts, USA\"\n",
    "locations_fix_dict[\"HERAKLION, CRETE, GREECE\"] = \"Crete, Greece\"\n",
    "locations_fix_dict[\"Podebrady (near Prague), Czech Republic\"] = \"Prague, Czech Republic\"\n",
    "locations_fix_dict[\"Holiday Inn Express & Suites Ottawa Airport, Canada\"] = \"Ottawa, Canada\"\n",
    "locations_fix_dict[\"University of Koblenz-Landau, Koblenz, G\"] = \"Koblenz-Landau, Koblenz, Germany\"\n",
    "locations_fix_dict[\"Houston, Texas,us\"] = \"Houston, Texas, USA\"\n",
    "locations_fix_dict[\"BHUBANESWAR, INDIA\"] = \"Bhubaneswar, Odisha, India\"\n",
    "locations_fix_dict[\"Millennium Hall, Addis Ababa ETHIOPIA\"] = \"Addis Ababa, Ethiopia\"\n",
    "locations_fix_dict[\"Neubiberg, Germany, Germany\"] = \"Neubiberg, Germany\"\n",
    "locations_fix_dict[\"9.6/11.6, Brno, Czech Republic\"] = \"Brno, Czech Republic\"\n",
    "locations_fix_dict[\"K.lo Alto,, California, USA\"] = \"K.lo Alto, California, USA\"\n",
    "locations_fix_dict[\"Kassel, 2.-6, Universität, Kassel\"] = \"Kassel, Germany\"\n",
    "locations_fix_dict[\"IBM Germany, Wildbad\"] = \"Wildbad, Germany\"\n",
    "locations_fix_dict[\"IBM Germany, Heidelberg\"] = \"Heidelberg, Germany\"\n",
    "locations_fix_dict[\"USA, Sendai, Japan\"] = \"Sendai, Japan\"\n",
    "locations_fix_dict[\"Los Angeles, USA, Studio\"] = \"Los Angeles, USA\"\n",
    "locations_fix_dict[\"Anaheim, USA, VR Village\"] = \"Anaheim, USA\"\n",
    "locations_fix_dict[\"Anaheim, USA, Studio\"] = \"Anaheim, USA\"\n",
    "locations_fix_dict[\"Orlando Area, Florida, United States\"] = \"Orlando, Florida, United States\"\n",
    "locations_fix_dict[\"San Diego, CA, United States\"] = \"San Diego, California, United States\"\n",
    "locations_fix_dict[\"Universidad de Zaragoza, Zaragoza, Spain\"] = \"Zaragoza, Spain\"\n",
    "locations_fix_dict[\"Eurasia, St. Petersburg, Russian Federation\"] = \"St. Petersburg, Russia\"\n",
    "locations_fix_dict[\"Danang, Viet Nam -\"] = \"Danang, Vietnam\"\n",
    "locations_fix_dict[\"Büro, Dresden\"] = \"Dresden, Germany\"\n",
    "locations_fix_dict[\"Büro, Oldenburg\"] = \"Oldenburg, Germany\"\n",
    "locations_fix_dict[\"Büro, Darmstadt\"] = \"Darmstadt, Germany\"\n",
    "locations_fix_dict[\"Büro, Braunschweig\"] = \"Braunschweig, Germany\"\n",
    "locations_fix_dict[\"Büro, Zürich\"] = \"Zürich, Switzerland\"\n",
    "locations_fix_dict[\"Büro, Freiburg\"] = \"Freiburg, Germany\"\n",
    "locations_fix_dict[\"Büro, Ulm\"] = \"Ulm, Germany\"\n",
    "locations_fix_dict[\"Modeling, Houston, TX, USA\"] = \"Houston, Texas, USA\"\n",
    "locations_fix_dict[\"Universal Village, Boston, MA, USA\"] = \"Boston, MA, USA\"\n",
    "locations_fix_dict[\"Ghent, Belgium (Virtual Event)\"] = \"Ghent, Belgium\"\n",
    "locations_fix_dict[\"Buenos Aires - Argentina\"] = \"Buenos Aires, Argentina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting the Fixed Locations to the Locations in the Original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.replace({\"ConferenceLocation\": locations_fix_dict})\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.replace({\"ConferenceLocation\": locations_fix_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of the Papers that Only Have the Conference State (But Not the Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_and_locations = df_citations_and_locations.drop(df_citations_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation by year and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_by_year_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.drop(df_citations_by_year_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the iindexes after the drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conference Location Automatic Cleanup and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the Distinct Conferences Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to extract the distinct conferences locations:<br>\n",
    "**Note**: since the two dataframes contain exactly the same papers and locations, the following operations are going to be executed only on a dataframe, and then replicated on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = df_citations_and_locations.drop_duplicates(subset=\"ConferenceLocation\")['ConferenceLocation'].tolist()\n",
    "\n",
    "locations_fix_dict = dict()\n",
    "\n",
    "for loc in locations_list:\n",
    "    locations_fix_dict[loc] = loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the Geolocator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"test_mail@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode(location, recursion=0, request_delay=None, *args, **kwargs):\n",
    "     # delay only between the first request. Otherwise, the normal sleep should have already been called\n",
    "    if request_delay and recursion == 0:\n",
    "        time.sleep(request_delay)\n",
    "\n",
    "    try:\n",
    "        return geolocator.geocode(location, *args, **kwargs)\n",
    "    except Exception:\n",
    "        if recursion > 10:      # max retry\n",
    "            return None\n",
    "\n",
    "        time.sleep(1) # wait before retrying\n",
    "        return geocode(location, recursion=recursion + 1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict[\"London, UK - UK\"] = \"London, UK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disambiguation and Normalization Using Geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Normalization Request 1 out of 5063: Austin, TX\n",
      "Normalized: Austin, Texas, United States\n",
      "\n",
      "Location Normalization Request 2 out of 5063: Wrocław, Poland\n",
      "Normalized: Wrocław, Lower Silesian Voivodeship, Poland\n",
      "\n",
      "Location Normalization Request 3 out of 5063: Innsbruck, Austria\n",
      "Normalized: Innsbruck, Tyrol, Austria\n",
      "\n",
      "Location Normalization Request 4 out of 5063: Provence, France\n",
      "Normalized: Villefranche-sur-Saône, Auvergne-Rhône-Alpes, France\n",
      "\n",
      "Location Normalization Request 5 out of 5063: Zakopane, Poland\n",
      "Normalized: Zakopane, Lesser Poland Voivodeship, Poland\n",
      "\n",
      "Location Normalization Request 6 out of 5063: Lisbon, Portugal\n"
     ]
    }
   ],
   "source": [
    "n_locations = locations_fix_dict.__len__()\n",
    "count = 1\n",
    "\n",
    "for loc in locations_fix_dict.keys():\n",
    "    print(f\"Location Normalization Request {count} out of {n_locations}: {locations_fix_dict[loc]}\")\n",
    "    count += 1\n",
    "\n",
    "    #print(\"Original: \" + locations_fix_dict[loc])\n",
    "\n",
    "    raw_location_dict = geocode(locations_fix_dict[loc], request_delay=1, language=\"en\", addressdetails=True, exactly_one=True, timeout=10)\n",
    "\n",
    "    normalized_loc = \"\"\n",
    "\n",
    "    city_ok = False\n",
    "\n",
    "    if raw_location_dict is None:\n",
    "        continue\n",
    "\n",
    "    for key in raw_location_dict.raw['address'].keys():\n",
    "        if key == \"city\" and not city_ok:\n",
    "            normalized_loc = raw_location_dict.raw['address'][key]\n",
    "            city_ok = True\n",
    "\n",
    "        elif key == \"municipality\" and not city_ok:\n",
    "            normalized_loc = raw_location_dict.raw['address'][key]\n",
    "            city_ok = True\n",
    "\n",
    "        elif key == \"town\" and not city_ok:\n",
    "            normalized_loc = raw_location_dict.raw['address'][key]\n",
    "            city_ok = True\n",
    "\n",
    "        else:        \n",
    "            if key == \"county\":\n",
    "                if normalized_loc.__len__() == 0:\n",
    "                    if normalized_loc != raw_location_dict.raw['address'][key]:\n",
    "                        if normalized_loc.__len__() != 0:\n",
    "                            normalized_loc += \", \"\n",
    "                        normalized_loc += raw_location_dict.raw['address'][key]\n",
    "\n",
    "            elif key == \"state\":\n",
    "                if normalized_loc.__len__() != 0:\n",
    "                    normalized_loc += \", \"\n",
    "                normalized_loc += raw_location_dict.raw['address'][key]\n",
    "\n",
    "            elif key == \"country\":\n",
    "                if normalized_loc.__len__() != 0:\n",
    "                    normalized_loc += \", \"\n",
    "                normalized_loc += raw_location_dict.raw['address'][key]\n",
    "\n",
    "    #print(raw_location_dict.raw['address']) # DEBUG\n",
    "    print(\"Normalized: \" + normalized_loc + \"\\n\")\n",
    "\n",
    "    locations_fix_dict[loc] = normalized_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting the Fixed Locations to the Locations in the Original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.replace({\"ConferenceLocation\": locations_fix_dict})\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.replace({\"ConferenceLocation\": locations_fix_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of the Papers that Only Have the Conference State (But Not the Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_and_locations = df_citations_and_locations.drop(df_citations_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation by year and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_by_year_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.drop(df_citations_by_year_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the iindexes after the drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write of the Final CSVs on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the resulting dataframe on disk in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write of the resulting CSVs on Disk\n",
    "df_citations_and_locations.to_csv(path_file_export + 'out_citations_and_conferences_location_ready.csv')\n",
    "print(f'Successfully Exported the Joined CSV to {path_file_export}out_citations_and_conferences_location_ready.csv')\n",
    "\n",
    "df_citations_by_year_and_locations.to_csv(path_file_export + 'out_citations_by_year_and_conferences_location_ready.csv')\n",
    "print(f'Successfully Exported the Joined CSV to {path_file_export}out_citations_by_year_and_conferences_location_ready.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the Exported CSVs to be sure that everything went fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of the Exported CSV\n",
    "df_joined_exported_csv_cit = pd.read_csv(path_file_export + 'out_citations_and_conferences_location_ready.csv', low_memory=False, index_col=[0])\n",
    "df_joined_exported_csv_cit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of the Exported CSV\n",
    "df_joined_exported_csv_cit_by_year = pd.read_csv(path_file_export + 'out_citations_by_year_and_conferences_location_ready.csv', low_memory=False, index_col=[0])\n",
    "df_joined_exported_csv_cit_by_year"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
