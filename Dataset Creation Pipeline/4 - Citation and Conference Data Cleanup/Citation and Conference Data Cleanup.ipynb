{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation and Conference Data Cleanup\n",
    "\n",
    "Microsoft Academics Graph and DBLP use two different scheme of rapresentation for the locations.\n",
    "\n",
    "For example, some locations are represented in the following format *City, State*, while while others in the *City, State, USA* format. Also, there are Locations that wrongly contains their Conference Name, that needs to be filtered, and so on.<br>\n",
    "\n",
    "These different formats create ambiguity that we need to solve.\n",
    "\n",
    "\n",
    "**TODO**\n",
    "\n",
    "Jupyter Notebook for the join of the conferences and location data between the DBLP + MAG and COCI dumps.\n",
    "\n",
    "For this process, the following CSV files are needed: ```out_coci_citations_count.csv``` and ```out_dblp_and_mag_joined.csv```. <br>\n",
    "The first must be generated running the Notebook ```preprocess_opencitations.ipynb``` that is contained in the ```1 - Citation Dumps Preprocess``` folder of this project.\n",
    "The above files must be generated running the ```1 - DBLP and MAG Data Join Notebook.ipynb``` Notebook that is contained in the same folder as this Notebook.\n",
    "\n",
    "In particular, the following operations are going to be executed:\n",
    "* Opening of the CSV preprocessed dumps\n",
    "* Join between the two datasets\n",
    "* Drop of the useless columns\n",
    "* Fix of the mismatched data types\n",
    "\n",
    "Lastly, the entire preprocessed dump is going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n",
    "Please set your working directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Import/COCI_RAW/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read of the Joined Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Imported the Conference Citations and Locations CSV\n",
      "Successfully Imported the Conference Citations by Year and Locations CSV\n"
     ]
    }
   ],
   "source": [
    "df_citations_and_locations = pd.read_csv(path_file_export + 'out_citations_and_conferences.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the Conference Citations and Locations CSV')\n",
    "\n",
    "df_citations_by_year_and_locations = pd.read_csv(path_file_export + 'out_citations_by_year_and_conferences.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the Conference Citations by Year and Locations CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Citations and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitationCount_COCI</th>\n",
       "      <th>CitationCount_Mag</th>\n",
       "      <th>CitationCount_MagEstimated</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceTitle</th>\n",
       "      <th>Doi</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>Distributed Computing - 28th International Sym...</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>Algorithms - ESA 2014 - 22th Annual European S...</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>Information and Communication Technologies in ...</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>SoCoMo Marketing for Travel and Tourism</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitationCount_COCI  CitationCount_Mag  CitationCount_MagEstimated  \\\n",
       "0                  10                 12                          12   \n",
       "1                   5                 10                          10   \n",
       "2                  11                 20                          20   \n",
       "\n",
       "   ConferenceLocation ConferenceNormalizedName  \\\n",
       "0          Austin, TX                disc 2014   \n",
       "1     Wrocław, Poland                 esa 2014   \n",
       "2  Innsbruck, Austria               enter 2013   \n",
       "\n",
       "                                     ConferenceTitle  \\\n",
       "0  Distributed Computing - 28th International Sym...   \n",
       "1  Algorithms - ESA 2014 - 22th Annual European S...   \n",
       "2  Information and Communication Technologies in ...   \n",
       "\n",
       "                            Doi  \\\n",
       "0  10.1007/978-3-662-45174-8_28   \n",
       "1  10.1007/978-3-662-44777-2_60   \n",
       "2  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "                                       OriginalTitle  Year  \n",
       "0  The Adaptive Priority Queue with Elimination a...  2014  \n",
       "1       Document Retrieval on Repetitive Collections  2014  \n",
       "2            SoCoMo Marketing for Travel and Tourism  2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Citations by Year and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceTitle</th>\n",
       "      <th>Doi</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>Year</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>Distributed Computing - 28th International Sym...</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>Algorithms - ESA 2014 - 22th Annual European S...</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>Information and Communication Technologies in ...</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>SoCoMo Marketing for Travel and Tourism</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConferenceLocation ConferenceNormalizedName  \\\n",
       "0          Austin, TX                disc 2014   \n",
       "1     Wrocław, Poland                 esa 2014   \n",
       "2  Innsbruck, Austria               enter 2013   \n",
       "\n",
       "                                     ConferenceTitle  \\\n",
       "0  Distributed Computing - 28th International Sym...   \n",
       "1  Algorithms - ESA 2014 - 22th Annual European S...   \n",
       "2  Information and Communication Technologies in ...   \n",
       "\n",
       "                            Doi  \\\n",
       "0  10.1007/978-3-662-45174-8_28   \n",
       "1  10.1007/978-3-662-44777-2_60   \n",
       "2  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "                                       OriginalTitle  Year  1950  1951  1952  \\\n",
       "0  The Adaptive Priority Queue with Elimination a...  2014     0     0     0   \n",
       "1       Document Retrieval on Repetitive Collections  2014     0     0     0   \n",
       "2            SoCoMo Marketing for Travel and Tourism  2013     0     0     0   \n",
       "\n",
       "   1953  1954  1955  1956  1957  1958  1959  1960  1961  1962  1963  1964  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1965  1966  1967  1968  1969  1970  1971  1972  1973  1974  1975  1976  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1977  1978  1979  1980  1981  1982  1983  1984  1985  1986  1987  1988  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1989  1990  1991  1992  1993  1994  1995  1996  1997  1998  1999  2000  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2001  2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  2012  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2013  2014  2015  2016  2017  2018  2019  2020  2021  2022  \n",
       "0     0     0     2     1     1     0     2     1     2     0  \n",
       "1     0     0     2     0     2     0     0     0     0     0  \n",
       "2     0     3     0     3     2     0     1     1     0     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_by_year_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop of the Useless Columns\n",
    "First of all, we're going to drop the columns that are not needed anymore.<br>\n",
    "The following columns are going to be removed:\n",
    "* ConferenceTitle: the full title of the conference. It's not defined for a lot a conferences.\n",
    "* OriginalTitle: the paper's title. It's not defined for the most of the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations.drop(columns=['ConferenceTitle', 'OriginalTitle'], inplace=True)\n",
    "df_citations_by_year_and_locations.drop(columns=['ConferenceTitle', 'OriginalTitle'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CitationCount_COCI</th>\n",
       "      <th>CitationCount_Mag</th>\n",
       "      <th>CitationCount_MagEstimated</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CitationCount_COCI  CitationCount_Mag  CitationCount_MagEstimated  \\\n",
       "0                  10                 12                          12   \n",
       "1                   5                 10                          10   \n",
       "2                  11                 20                          20   \n",
       "\n",
       "   ConferenceLocation ConferenceNormalizedName                           Doi  \\\n",
       "0          Austin, TX                disc 2014  10.1007/978-3-662-45174-8_28   \n",
       "1     Wrocław, Poland                 esa 2014  10.1007/978-3-662-44777-2_60   \n",
       "2  Innsbruck, Austria               enter 2013  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "   Year  \n",
       "0  2014  \n",
       "1  2014  \n",
       "2  2013  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ConferenceLocation ConferenceNormalizedName                           Doi  \\\n",
       "0          Austin, TX                disc 2014  10.1007/978-3-662-45174-8_28   \n",
       "1     Wrocław, Poland                 esa 2014  10.1007/978-3-662-44777-2_60   \n",
       "2  Innsbruck, Austria               enter 2013  10.1007/978-3-319-03973-2_13   \n",
       "\n",
       "   Year  1950  1951  1952  1953  1954  1955  1956  1957  1958  1959  1960  \\\n",
       "0  2014     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1  2014     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2  2013     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  1971  1972  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1973  1974  1975  1976  1977  1978  1979  1980  1981  1982  1983  1984  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1985  1986  1987  1988  1989  1990  1991  1992  1993  1994  1995  1996  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   1997  1998  1999  2000  2001  2002  2003  2004  2005  2006  2007  2008  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2009  2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  \\\n",
       "0     0     0     0     0     0     0     2     1     1     0     2     1   \n",
       "1     0     0     0     0     0     0     2     0     2     0     0     0   \n",
       "2     0     0     0     0     0     3     0     3     2     0     1     1   \n",
       "\n",
       "   2021  2022  \n",
       "0     2     0  \n",
       "1     0     0  \n",
       "2     0     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations_by_year_and_locations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conference Location Manual Cleanup\n",
    "Before submitting the location data to an automatic location recognizer, I decided to manually cleanup and filter the most of the issues I found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to filter the papers that do not have a location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation filtered about 1.5M of rows\n"
     ]
    }
   ],
   "source": [
    "original_rows = df_citations_and_locations.index.__len__()\n",
    "\n",
    "df_citations_and_locations = df_citations_and_locations[df_citations_and_locations['ConferenceLocation'].notna()]\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations[df_citations_by_year_and_locations['ConferenceLocation'].notna()]\n",
    "\n",
    "actual_rows = df_citations_and_locations.index.__len__()\n",
    "\n",
    "print(f\"The operation filtered about {round(((original_rows - actual_rows) / 1000000), 1)}M of rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the Distinct Conferences Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to extract the distinct conferences locations:<br>\n",
    "**Note**: since the two dataframes contain exactly the same papers and locations, the following operations are going to be executed only on a dataframe, and then replicated on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = df_citations_and_locations.drop_duplicates(subset=\"ConferenceLocation\")['ConferenceLocation'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the locations that only have the state (but don't have the city): the don't need to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_locations_list = list()\n",
    "\n",
    "for loc in locations_list:\n",
    "    if loc.split(',').__len__() >= 2:\n",
    "        new_locations_list.append(loc)\n",
    "\n",
    "locations_list = new_locations_list\n",
    "new_locations_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a Support Dictionary\n",
    "We're going to create a support dictionary that's going to contain the locations and their fixed name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict = dict()\n",
    "\n",
    "for loc in locations_list:\n",
    "    locations_fix_dict[loc] = loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix of the Locations in the Format \"City,state_acronym\"\n",
    "Some locations are in the format \"City,state_acronym\". We need to convert them to \"City, STATE_ACRONYM\".\n",
    "\n",
    "For example: \"Hamilton,nz\" to \"Hamilton, NZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    if locations_fix_dict[loc].split(',').__len__() == 2 and locations_fix_dict[loc].split(',')[1].__len__() == 2:\n",
    "        locations_fix_dict[loc] = str(locations_fix_dict[loc].split(',')[0] + ', ' + locations_fix_dict[loc].split(',')[1].upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix of Some Extra Spacings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(' ,', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of the \"- United State of America\" and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\" - United States of America\", \"\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\" - United States\", \"\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\" - United Kingdom of Great Britain and Northern Ireland\", \"\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"Netherlands - Kingdom of the Netherlands\", \"The Netherlands\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"The Netherlands - Including\", \"The Netherlands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US, USA, U.S.A., U.S. and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"United States\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"USA\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S.A.\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S.A\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"USA.\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S.\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.S\", \"US\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"US\", \"USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### United Kingdom, Great Bretain, and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"GB\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"United Kingdom\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"England\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.K.\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"U.K\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"G.B.\", \"UK\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"G.B\", \"UK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### South Korea and Other Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"S.Korea\", \"Korea (South)\")\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"S. Korea\", \"Korea (South)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"(near Place)\" Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some places are in the following format: \"place_name (near big_town_name), [...]\"\n",
    "\n",
    "We need to convert them in the following format: \"big_town_name, [...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    if \" (near \" in locations_fix_dict[loc]:\n",
    "        locations_fix_dict[loc] = locations_fix_dict[loc].split(\" (near \")[1].split(\")\")[0] + locations_fix_dict[loc].split(\" (near \")[1].split(\")\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"near Place\" Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some places are in the following format: \"place_name near big_town_name, [...]\"\n",
    "\n",
    "We need to convert them in the following format: \"big_town_name, [...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    if \" near \" in locations_fix_dict[loc]:\n",
    "        locations_fix_dict[loc] = locations_fix_dict[loc].split(\" near \")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the Conference Name\n",
    "There are a small number of cases where the location wrongly contains the conference name. We need to filter it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we try to filter some caases automatically.\n",
    "\n",
    "In fact, in the most of the cases we have two formats:\n",
    "* \"CONF_NAME YEAR, Location\"\n",
    "* \"CONF_NAME'YEAR, Location\"\n",
    "* \"CONF_NAME-YEAR, Location\"\n",
    "* \"CONF_NAME, Location\": we'll address this case manually, since they are difficult to be distinguished from the normal locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "\n",
    "    count = 0\n",
    "    loc_splitted_list = locations_fix_dict[loc].split(',')\n",
    "    needs_to_be_fixed = False\n",
    "\n",
    "    if loc_splitted_list.__len__() >= 2:\n",
    "\n",
    "        # Here we check the \"CONF_NAME YEAR, Location\" format\n",
    "        if loc_splitted_list[0].split(' ').__len__() == 2 and loc_splitted_list[0].split(' ')[1].isnumeric():\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        # Here we check the \"CONF_NAME'YEAR, Location\" format\n",
    "        if loc_splitted_list[0].split(\"'\").__len__() == 2 and loc_splitted_list[0].split(\"'\")[1].isnumeric():\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        # Here we check the \"CONF_NAME-YEAR, Location\" format\n",
    "        if loc_splitted_list[0].split('-').__len__() == 2 and loc_splitted_list[0].split('-')[1].isnumeric():\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if needs_to_be_fixed:\n",
    "            locations_fix_dict[loc] = \"\"\n",
    "\n",
    "            for el in loc_splitted_list:\n",
    "                if count == 0:\n",
    "                    pass # the first element is the conference name\n",
    "                else:\n",
    "                    if str(el)[0] == ' ':\n",
    "                        el = str(el)[1:] # Filtering the blank space\n",
    "                        \n",
    "                    if count == 1: # the first doesn't need the comma\n",
    "                        locations_fix_dict[loc] += el\n",
    "                    else:\n",
    "                        locations_fix_dict[loc] += ', ' + el\n",
    "                \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addressing other special conferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "\n",
    "    count = 0\n",
    "    loc_splitted_list = locations_fix_dict[loc].split(',')\n",
    "    needs_to_be_fixed = False\n",
    "\n",
    "    if loc_splitted_list.__len__() >= 2:\n",
    "\n",
    "        if \"ASIC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"COIN@AAMAS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IEEE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"EvoSTOC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IIT\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"VLSI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"EvoFIN\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IST\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IMC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DEXA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CAMS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ACM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SC11\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SCIDOCA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CBD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"TBD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WAIM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"KAIST\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CompSysTech\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ESupercomputing\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"HEC2016\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"BIRTE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IWANN2003\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Web3D\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WoTUG\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"XSEDE13\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DBISP2P\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Erlang\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CNAM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"PX/16\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SESoS@ECOOP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WISE9\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CDT&SECOMANE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Reengineering\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Multimedia\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Mobile\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WBICV\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DCSA, DC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"FHPCN\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WISA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"P^3MA, WOPSSS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WOPSSS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"HardBD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MoDeVVa\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"QLD\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"FedCSIS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ReConFig14\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WGLBWS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ETAPS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SoMeT_17\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"PARLE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Banff\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Informatics\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"NLP&DBpedia\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SIGGRAPH\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DNA8\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SGAI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DCNET\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Meta4eS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ARRAY@PLDI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ALSIP, SocNet, BigPMA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ITiCSE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Supercomputersystemen\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ITEE2013\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"CSP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Algorithmics\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"China\" in loc_splitted_list[0]: # not a conference, but threated in the same way\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"UK\" in loc_splitted_list[0]: # not a conference, but threated in the same way\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"BigNovelTI, SW4CH\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SW4CH\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"M2P\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Society\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"IoTPTS@AsiaCCS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"PPREW@ACSAC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Eurasia\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"DUI\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Parallel\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Education\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Humanity\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"NLP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MSA\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Modeling\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MoDIC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WM2SP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"QoIS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ETheCoM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"XSDM\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Virtual Event\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Workshops\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"1992\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"SMAP\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"MaLTeSQuE@SANER\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Mobile\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"TRNC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"the UK & Ireland Computing Education Research Conference\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"WBDB.cn\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"QUOVADIS\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ULSSIS@ICSE\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"Training\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "        elif \"ICoC\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if needs_to_be_fixed:\n",
    "            locations_fix_dict[loc] = \"\"\n",
    "\n",
    "            for el in loc_splitted_list:\n",
    "                if count == 0:\n",
    "                    pass # the first element is the conference name\n",
    "                else:\n",
    "                    if str(el)[0] == ' ':\n",
    "                        el = str(el)[1:] # Filtering the blank space\n",
    "                        \n",
    "                    if count == 1: # the first doesn't need the comma\n",
    "                        locations_fix_dict[loc] += el\n",
    "                    else:\n",
    "                        locations_fix_dict[loc] += ', ' + el\n",
    "                \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virtual events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "    locations_fix_dict[loc] = locations_fix_dict[loc].replace(\"Virtual Event / \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict[\"York, UK / 2nd AAMAS 2002\"] = \"York, UK\"\n",
    "locations_fix_dict[\"Eugene, OR, USA / 2nd IWOMP 2006\"] = \"Eugene, OR, USA\"\n",
    "locations_fix_dict[\"Ausbildung, INFOS'95, Chemnitz\"] = \"Ausbildung, Chemnitz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in locations_fix_dict.keys():\n",
    "\n",
    "    count = 0\n",
    "    loc_splitted_list = locations_fix_dict[loc].split(',')\n",
    "    needs_to_be_fixed = False\n",
    "\n",
    "    if loc_splitted_list.__len__() >= 2:\n",
    "\n",
    "        if \"University of \" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if \" University\" in loc_splitted_list[0]:\n",
    "            needs_to_be_fixed = True\n",
    "\n",
    "        if needs_to_be_fixed:\n",
    "            locations_fix_dict[loc] = loc_splitted_list[0].replace(\"University of \", \"\")\n",
    "            locations_fix_dict[loc] = loc_splitted_list[0].replace(\" University\", \"\")\n",
    "\n",
    "            for el in loc_splitted_list:\n",
    "                if count >= 1:\n",
    "                    if str(el)[0] == ' ':\n",
    "                        el = str(el)[1:] # Filtering the blank space\n",
    "                        \n",
    "                        locations_fix_dict[loc] += ', ' + el\n",
    "                \n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Fix of the Special Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cases here are of various kind. We can have some mismatched caracter cases, or wrong spacings, or the indication of the place of the conference (such as hotels, etc).\n",
    "\n",
    "These cases need to be addressed one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_fix_dict[\"Lyon,\\xa0France\"] = \"Lyon, France\"\n",
    "locations_fix_dict[\"Workshops, Montreal, QC, Canada\"] = \"Montreal, QC, Canada\"\n",
    "locations_fix_dict[\", USA\"] = \"USA\"\n",
    "locations_fix_dict[\"NEW ORLEANS, USA\"] = \"New Orleans, USA\"\n",
    "locations_fix_dict[\"NOIDA, India\"] = \"Noida, India\"\n",
    "locations_fix_dict[\"CANCUN, Mexico\"] = \"Cancun, Mexico\"\n",
    "locations_fix_dict[\"Auckland, New Zealand, 8-12 August 2016\"] = \"Auckland, New Zealand\"\n",
    "locations_fix_dict[\"IOWA STATE UNIVERSITY, USA\"] = \"Iowa State University, USA\"\n",
    "locations_fix_dict[\"No.1, Dai Co Viet Rd, Hanoi, Vietnam\"] = \"Dai Co Viet Rd, Hanoi, Vietnam\"\n",
    "locations_fix_dict[\"GUANGZHOU,CHINA\"] = \"Guangzhou, China\"\n",
    "locations_fix_dict[\"Guilin,Guangxi, China\"] = \"Guilin, Guangxi, China\"\n",
    "locations_fix_dict[\"Gyeongju, Republic of Korea - March\"] = \"Gyeongju, Republic of Korea\"\n",
    "locations_fix_dict[\"Pune, INDIA\"] = \"Pune, India\"\n",
    "locations_fix_dict[\"International, Athens, Greece\"] = \"Athens, Greece\"\n",
    "locations_fix_dict[\"Tokyo, JAPAN\"] = \"Tokyo, Japan\"\n",
    "locations_fix_dict[\"Bangkok, THAILAND\"] = \"Bangkok, Thailand\"\n",
    "locations_fix_dict[\"Harbin,China\"] = \"Harbin, China\"\n",
    "locations_fix_dict[\"Washington, D. C., USA\"] = \"Washington D.C., USA\"\n",
    "locations_fix_dict[\"Funchal, Madeira - Portugal\"] = \"Funchal, Madeira, Portugal\"\n",
    "locations_fix_dict[\"Kuantan, Pahang, MALAYSIA\"] = \"Kuantan, Pahang, Malaysia\"\n",
    "locations_fix_dict[\"LEIPZIG, GERMANY\"] = \"Leipzig, Germany\"\n",
    "locations_fix_dict[\"THESSALONIKI, GREECEY\"] = \"Thessaloniki, Greece\"\n",
    "locations_fix_dict[\"Phoenix Park, PyeongChang,, Korea (South)\"] = \"Phoenix Park, PyeongChang, Korea (South)\"\n",
    "locations_fix_dict[\"EvoFIN, EvoSTOC, Germany\"] = \"Germany\"\n",
    "locations_fix_dict[\"Prague,\"] = \"Prague\"\n",
    "locations_fix_dict[\", York, UK\"] = \"York, UK\"\n",
    "locations_fix_dict[\"Royal Continental Hotel,Naples, Italy\"] = \"Naples, Italy\"\n",
    "locations_fix_dict[\"Puebla, MEXICO\"] = \"Puebla, Mexico\"\n",
    "locations_fix_dict[\"Jun 16-20, 2008\"] = \"\"\n",
    "locations_fix_dict[\"Taipei, Taiwan, August 29-31, 2012.\"] = \"Taipei, Taiwan\"\n",
    "locations_fix_dict[\"YORK, UK\"] = \"York, UK\"\n",
    "locations_fix_dict[\"Kuala Lumpur, Malaysia.\"] = \"Kuala Lumpur, Malaysia\"\n",
    "locations_fix_dict[\"Brisbane Convention & Exhibition Centre, Brisbane, Australia\"] = \"Brisbane, Australia\"\n",
    "locations_fix_dict[\"Vienna University of Technology, Vienna\"] = \"Vienna, Austria\"\n",
    "locations_fix_dict[\"Hammamet,Tunisia\"] = \"Hammamet, Tunisia\"\n",
    "locations_fix_dict[\"MIT, Cambridge, USA\"] = \"Cambridge, USA\"\n",
    "locations_fix_dict[\"Cumbria, United, Kngdm\"] = \"Cumbria, UK\"\n",
    "locations_fix_dict[\"Hilton Hotel Cyprus, Nicosia\"] = \"Cyprus, Nicosia\"\n",
    "locations_fix_dict[\"changsha, China\"] = \"Changsha, China\"\n",
    "locations_fix_dict[\"PADERBORN, GERMANY\"] = \"Paderborn, Germany\"\n",
    "locations_fix_dict[\"DA NANG, Vietnam\"] = \"Da Nang, Vietnam\"\n",
    "locations_fix_dict[\"Durham, NC USA\"] = \"Durham, NC, USA\"\n",
    "locations_fix_dict[\"International, Mykonos Island, Greece\"] = \"Mykonos Island, Greece\"\n",
    "locations_fix_dict[\"GUNTUR, Vijayawada, PIN 622510,in\"] = \"Vijayawada, IN\"\n",
    "locations_fix_dict[\"Bolzano-Bozen, Italy\"] = \"Bolzen, Italy\"\n",
    "locations_fix_dict[\"Providence, RI,\"] = \"Providence, RI\"\n",
    "locations_fix_dict[\"Adisaptagram, Hooghly - 712121, India\"] = \"Adisaptagram, Hooghly, India\"\n",
    "locations_fix_dict[\"Alexandria, Virginia, U.S.\"] = \"Alexandria, Virginia, USA\"\n",
    "locations_fix_dict[\"guilin, china\"] = \"Guilin, China\"\n",
    "locations_fix_dict[\"Washington, D.C. (USA)\"] = \"Washington D.C., USA\"\n",
    "locations_fix_dict[\"San, Diego, CA, USA\"] = \"San Diego, CA, USA\"\n",
    "locations_fix_dict[\"Kinsdale,\"] = \"Kinsdale\"\n",
    "locations_fix_dict[\"Bhubaneswar,India.\"] = \"Bhubaneswar, India\"\n",
    "locations_fix_dict[\"Florence, ITALY\"] = \"Florence, Italy\"\n",
    "locations_fix_dict[\"Munich,de\"] = \"Munich, DE\"\n",
    "locations_fix_dict[\"Crete, GREECE\"] = \"Crete, Greece\"\n",
    "locations_fix_dict[\"Montreal, QC, CANADA\"] = \"Montreal, QC, Canada\"\n",
    "locations_fix_dict[\"Beijing, People's Republic of China\"] = \"Beijing, China\"\n",
    "locations_fix_dict[\"Ceske Budejovice,cz\"] = \"Ceske Budejovice, CZ\"\n",
    "locations_fix_dict[\"MEXICO CITY, Mexico\"] = \"Mexico City, Mexico\"\n",
    "locations_fix_dict[\"DARMSTADT, Germany.\"] = \"Darmstadt, Germany\"\n",
    "locations_fix_dict[\"singapore, Singapore\"] = \"Singapore, Singapore\"\n",
    "locations_fix_dict[\"St.-Petersburg, Russia\"] = \"St. Petersburg, Russia\"\n",
    "locations_fix_dict[\"Suwon, Korea,\"] = \"Suwon, Korea\"\n",
    "locations_fix_dict[\"Curium Palace Hotel, Limassol, Cyprus\"] = \"Limassol, Cyprus\"\n",
    "locations_fix_dict[\"Vilanova i la Geltru, Barcelona, Spain\"] = \"Barcelona, Spain\"\n",
    "locations_fix_dict[\"Vancouver Convention Center, Vancouver CANADA \"] = \"Vancouver, Canada\"\n",
    "locations_fix_dict[\"Denver,CO,USA\"] = \"Denver, CO, USA\"\n",
    "locations_fix_dict[\"San Francisco, U.S.A\"] = \"San Francisco, USA\"\n",
    "locations_fix_dict[\"Chiang Mai,, Thailand\"] = \"Chiang Mai, Thailand\"\n",
    "locations_fix_dict[\"DIVANI PALACE ACROPOLIS Athens, Greece\"] = \"Athens, Greece\"\n",
    "locations_fix_dict[\"Greenwich, London (UK)\"] = \"London, UK\"\n",
    "locations_fix_dict[\"Madrid,Spain\"] = \"Madrid, Spain\"\n",
    "locations_fix_dict[\"Chongqing,China\"] = \"Chongqing, China\"\n",
    "locations_fix_dict[\"Training, Atlanta, GA, USA\"] = \"Atlanta, GA, USA\"\n",
    "locations_fix_dict[\"denver, CA, USA\"] = \"Denver, CA, USA\"\n",
    "locations_fix_dict[\"HANGZHOU, PEOPLE'S REPUBLIC OF CHINA\"] = \"Hangzhou, China\"\n",
    "locations_fix_dict[\"Portland, Oregon, June 18-19, 2015\"] = \"Portland, Oregon\"\n",
    "locations_fix_dict[\"UK, Guildford, United Kingdom\"] = \"Guildford, UK\"\n",
    "locations_fix_dict[\"London (Guildford), United Kingdom\"] = \"London, UK\"\n",
    "locations_fix_dict[\"MIT, Cambridge, U.S.A\"] = \"Cambridge, USA\"\n",
    "locations_fix_dict[\"54 on Bath, Rosebank, Johannesburg, South Africa\"] = \"Rosebank, Johannesburg, South Africa\"\n",
    "locations_fix_dict[\"hONOLULU, hAWAII\"] = \"Honolulu, Hawaii\"\n",
    "locations_fix_dict[\"Hefei, P.R.China\"] = \"Hefei, China\"\n",
    "locations_fix_dict[\"National Ilan Unviersity, I-Lan, Taiwan\"] = \"I-Lan, Taiwan\"\n",
    "locations_fix_dict[\"Galt House Hotel, Louisville, Kentucky, USA - United States\"] = \"Kentucky, USA - United States\"\n",
    "locations_fix_dict[\"HIROSHIMA, JAPAN\"] = \"Hiroshima, Japan\"\n",
    "locations_fix_dict[\"UK, Bradford, UK\"] = \"Bradford, UK\"\n",
    "locations_fix_dict[\"ETH Zürich, Zurich, Switzerland\"] = \"Zurich, Switzerland\"\n",
    "locations_fix_dict[\"Tehran, IRAN\"] = \"Tehran, Iran\"\n",
    "locations_fix_dict[\"Bolzen, Italy\"] = \"Bolzen, Italy\"\n",
    "locations_fix_dict[\"THE FAIRMONT, SAN JOSE, CA\"] = \"San Jose, CA\"\n",
    "locations_fix_dict[\"Shenzhen, China (collocated with HPCA)\"] = \"Shenzhen, China\"\n",
    "locations_fix_dict[\"Birmingham City Univ, UK\"] = \"Birmingham, UK\"\n",
    "locations_fix_dict[\"Dublin City, Univ., Ireland\"] = \"Dublin, Ireland\"\n",
    "locations_fix_dict[\"BARCELONA, SPAIN\"] = \"Barcelona, Spain\"\n",
    "locations_fix_dict[\"Saint John's, Newfoundland and Labrador,\"] = \"\"\n",
    "locations_fix_dict[\"ANNECY, FRANCE - IMPERIAL PALACE\"] = \"Annecy, France\"\n",
    "locations_fix_dict[\"Dubai,UAE\"] = \"Dubai, UAE\"\n",
    "locations_fix_dict[\"Nanyang Technological University, Singapore\"] = \"Nanyang, Singapore\"\n",
    "locations_fix_dict[\"SINGAPORE, Singapore\"] = \"Singapore, Singapore\"\n",
    "locations_fix_dict[\"San Francisco Bay Area, USA\"] = \"San Francisco, USA\"\n",
    "locations_fix_dict[\"TU Berlin, Berlin, Germany\"] = \"Berlin, Germany\"\n",
    "locations_fix_dict[\"Grecian Bay Hotel, Ayia Napa, Cyprus\"] = \"Ayia Napa, Cyprus\"\n",
    "locations_fix_dict[\"Aristi Village, Zagorochoria, Greece\"] = \"Zagorochoria, Greece\"\n",
    "locations_fix_dict[\"KENITRA, MA\"] = \"Kinitra, MA\"\n",
    "locations_fix_dict[\"Exeter College, Oxford, UK - UK\"] = \"Exeter College, Oxford, UK\"\n",
    "locations_fix_dict[\"2008\"] = \"\"\n",
    "locations_fix_dict[\"UK, Edinburgh, UK\"] = \"Edinburgh, UK\"\n",
    "locations_fix_dict[\"Bhubaneswar,Odisha, India\"] = \"Bhubaneswar, Odisha, India\"\n",
    "locations_fix_dict[\"Hyatt Harborside, Boston, Massachusetts, USA\"] = \"Boston, Massachusetts, USA\"\n",
    "locations_fix_dict[\"HERAKLION, CRETE, GREECE\"] = \"Crete, Greece\"\n",
    "locations_fix_dict[\"Podebrady (near Prague), Czech Republic\"] = \"Prague, Czech Republic\"\n",
    "locations_fix_dict[\"Holiday Inn Express & Suites Ottawa Airport, Canada\"] = \"Ottawa, Canada\"\n",
    "locations_fix_dict[\"University of Koblenz-Landau, Koblenz, G\"] = \"Koblenz-Landau, Koblenz, Germany\"\n",
    "locations_fix_dict[\"Houston, Texas,us\"] = \"Houston, Texas, USA\"\n",
    "locations_fix_dict[\"BHUBANESWAR, INDIA\"] = \"Bhubaneswar, Odisha, India\"\n",
    "locations_fix_dict[\"Millennium Hall, Addis Ababa ETHIOPIA\"] = \"Addis Ababa, Ethiopia\"\n",
    "locations_fix_dict[\"Barcelona, SPAIN\"] = \"Barcelona, Spaiin\"\n",
    "locations_fix_dict[\"International, Budapest, Hungary\"] = \"Budapest, Hungary\"\n",
    "locations_fix_dict[\"TURIN, Italy\"] = \"Turin, Italy\"\n",
    "locations_fix_dict[\"BOISE, ID, USA\"] = \"Boise, ID, USA\"\n",
    "locations_fix_dict[\"Neubiberg, Germany, Germany\"] = \"Neubiberg, Germany\"\n",
    "locations_fix_dict[\"9.6/11.6, Brno, Czech Republic\"] = \"Brno, Czech Republic\"\n",
    "locations_fix_dict[\"K.lo Alto,, California, USA\"] = \"K.lo Alto, California, USA\"\n",
    "locations_fix_dict[\"Kassel, 2.-6, Universität, Kassel\"] = \"Kassel, Germany\"\n",
    "locations_fix_dict[\"IBM Germany, Wildbad\"] = \"Wildbad, Germany\"\n",
    "locations_fix_dict[\"IBM Germany, Heidelberg\"] = \"Heidelberg, Germany\"\n",
    "locations_fix_dict[\"USA, Sendai, Japan\"] = \"Sendai, Japan\"\n",
    "locations_fix_dict[\"Los Angeles, USA, Studio\"] = \"Los Angeles, USA\"\n",
    "locations_fix_dict[\"Anaheim, USA, VR Village\"] = \"Anaheim, USA\"\n",
    "locations_fix_dict[\"Anaheim, USA, Studio\"] = \"Anaheim, USA\"\n",
    "locations_fix_dict[\"Orlando Area, Florida, United States\"] = \"Orlando, Florida, United States\"\n",
    "locations_fix_dict[\"San Diego, CA, United States\"] = \"San Diego, California, United States\"\n",
    "locations_fix_dict[\"Universidad de Zaragoza, Zaragoza, Spain\"] = \"Zaragoza, Spain\"\n",
    "locations_fix_dict[\"Eurasia, St. Petersburg, Russian Federation\"] = \"St. Petersburg, Russia\"\n",
    "locations_fix_dict[\"Danang, Viet Nam -\"] = \"Danang, Vietnam\"\n",
    "locations_fix_dict[\"Büro, Dresden\"] = \"Dresden, Germany\"\n",
    "locations_fix_dict[\"Büro, Oldenburg\"] = \"Oldenburg, Germany\"\n",
    "locations_fix_dict[\"Büro, Darmstadt\"] = \"Darmstadt, Germany\"\n",
    "locations_fix_dict[\"Büro, Braunschweig\"] = \"Braunschweig, Germany\"\n",
    "locations_fix_dict[\"Büro, Zürich\"] = \"Zürich, Switzerland\"\n",
    "locations_fix_dict[\"Büro, Freiburg\"] = \"Freiburg, Germany\"\n",
    "locations_fix_dict[\"Büro, Ulm\"] = \"Ulm, Germany\"\n",
    "locations_fix_dict[\"Modeling, Houston, TX, USA\"] = \"Houston, Texas, USA\"\n",
    "locations_fix_dict[\"Universal Village, Boston, MA, USA\"] = \"Boston, MA, USA\"\n",
    "locations_fix_dict[\"Ghent, Belgium (Virtual Event)\"] = \"Ghent, Belgium\"\n",
    "locations_fix_dict[\"Buenos Aires - Argentina\"] = \"Buenos Aires, Argentina\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction of the Locations in the Original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.replace({\"ConferenceLocation\": locations_fix_dict})\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.replace({\"ConferenceLocation\": locations_fix_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of the Papers that Only Have the Conference State (But Not the Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_and_locations = df_citations_and_locations.drop(df_citations_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation by year and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_by_year_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.drop(df_citations_by_year_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the iindexes after the drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conference Location Automatic Cleanup and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the Distinct Conferences Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to extract the distinct conferences locations:<br>\n",
    "**Note**: since the two dataframes contain exactly the same papers and locations, the following operations are going to be executed only on a dataframe, and then replicated on the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = df_citations_and_locations.drop_duplicates(subset=\"ConferenceLocation\")['ConferenceLocation'].tolist()\n",
    "\n",
    "locations_fix_dict = dict()\n",
    "\n",
    "for loc in locations_list:\n",
    "    locations_fix_dict[loc] = loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Austin, TX\n",
      "{'city': 'Austin', 'county': 'Travis County', 'state': 'Texas', 'ISO3166-2-lvl4': 'US-TX', 'country': 'United States', 'country_code': 'us'}\n",
      "Austin, Travis County, Texas, United States\n",
      "\n",
      "Original: Wrocław, Poland\n",
      "{'municipality': 'Wrocław', 'county': 'Wrocław', 'state': 'Lower Silesian Voivodeship', 'ISO3166-2-lvl4': 'PL-02', 'country': 'Poland', 'country_code': 'pl'}\n",
      "Wrocław, Lower Silesian Voivodeship, Poland\n",
      "\n",
      "Original: Innsbruck, Austria\n",
      "{'city': 'Innsbruck', 'state': 'Tyrol', 'country': 'Austria', 'country_code': 'at'}\n",
      "Innsbruck, Tyrol, Austria\n",
      "\n",
      "Original: Provence, France\n",
      "{'isolated_dwelling': 'Provence', 'village': 'Marchampt', 'municipality': 'Villefranche-sur-Saône', 'county': 'Rhône', 'state_district': 'Departemental constituency of Rhône', 'state': 'Auvergne-Rhône-Alpes', 'region': 'Metropolitan France', 'postcode': '69430', 'country': 'France', 'country_code': 'fr'}\n",
      "Villefranche-sur-Saône, Rhône, Auvergne-Rhône-Alpes, France\n",
      "\n",
      "Original: Zakopane, Poland\n",
      "{'town': 'Zakopane', 'municipality': 'Zakopane', 'county': 'Tatra County', 'state': 'Lesser Poland Voivodeship', 'ISO3166-2-lvl4': 'PL-12', 'postcode': '34-500', 'country': 'Poland', 'country_code': 'pl'}\n",
      "Zakopane, Tatra County, Lesser Poland Voivodeship, Poland\n",
      "\n",
      "Original: Lisbon, Portugal\n",
      "{'city': 'Lisbon', 'county': 'Lisbon', 'postcode': '1100-148', 'country': 'Portugal', 'country_code': 'pt'}\n",
      "Lisbon, Portugal\n",
      "\n",
      "Original: Lübeck, Germany\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim(user_agent=\"test_mail@gmail.com\")\n",
    "\n",
    "for loc in locations_fix_dict.keys():\n",
    "    print(\"Original: \" + locations_fix_dict[loc])\n",
    "\n",
    "    raw_location_dict = geolocator.geocode(loc, language=\"en\", addressdetails=True, exactly_one=True)\n",
    "\n",
    "    normalized_loc = \"\"\n",
    "\n",
    "    city_ok = False\n",
    "\n",
    "    if raw_location_dict is None:\n",
    "        continue\n",
    "\n",
    "    for key in raw_location_dict.raw['address'].keys():\n",
    "        if key == \"city\" and not city_ok:\n",
    "            normalized_loc = raw_location_dict.raw['address'][key]\n",
    "            city_ok = True\n",
    "\n",
    "        elif key == \"municipality\" and not city_ok:\n",
    "            normalized_loc = raw_location_dict.raw['address'][key]\n",
    "            city_ok = True\n",
    "\n",
    "        elif key == \"town\" and not city_ok:\n",
    "            normalized_loc = raw_location_dict.raw['address'][key]\n",
    "            city_ok = True\n",
    "\n",
    "        else:        \n",
    "            if key == \"county\":\n",
    "                if normalized_loc != raw_location_dict.raw['address'][key]:\n",
    "                    if normalized_loc.__len__() != 0:\n",
    "                        normalized_loc += \", \"\n",
    "                    normalized_loc += raw_location_dict.raw['address'][key]\n",
    "\n",
    "            elif key == \"state\":\n",
    "                if normalized_loc.__len__() != 0:\n",
    "                    normalized_loc += \", \"\n",
    "                normalized_loc += raw_location_dict.raw['address'][key]\n",
    "\n",
    "            elif key == \"country\":\n",
    "                if normalized_loc.__len__() != 0:\n",
    "                    normalized_loc += \", \"\n",
    "                normalized_loc += raw_location_dict.raw['address'][key]\n",
    "\n",
    "    print(raw_location_dict.raw['address'])\n",
    "        \n",
    "    print(normalized_loc + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter of the Papers that Only Have the Conference State (But Not the Cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_and_locations = df_citations_and_locations.drop(df_citations_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row drop for the citation by year and locations dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_be_dropped_list = list()\n",
    "\n",
    "for index, row in df_citations_by_year_and_locations.iterrows():\n",
    "    if row[\"ConferenceLocation\"].split(',').__len__() < 2:\n",
    "        row_to_be_dropped_list.append(index)\n",
    "\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.drop(df_citations_by_year_and_locations.index[row_to_be_dropped_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the iindexes after the drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citations_and_locations = df_citations_and_locations.reset_index(drop=True)\n",
    "df_citations_by_year_and_locations = df_citations_by_year_and_locations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read of the DBLP + MAG CSV Joined Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_with_partial_csv:\n",
    "    new_df_joined_partial = pd.read_csv(partial_csv_path + 'out_citations_by_year_and_conferences.csv', low_memory=False, index_col=[0])\n",
    "    print(f'Successfully Imported the Partial CSV')\n",
    "\n",
    "df_joined = pd.read_csv(path_file_export + 'out_dblp_and_mag_joined.csv', low_memory=False, index_col=[0])\n",
    "print(f'Successfully Imported the DBLP + MAG CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the Support Dataframe\n",
    "It's going to help us extracting the citation' year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop of the useless mag citations column\n",
    "df_joined = df_joined.drop(columns=['CitationCount_Mag', 'CitationCount_MagEstimated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create the columns that are going to contain the citation obtained by a paper during a specific year. Also, needed for filtering the COCI paper that are not contained neither and MAG or DBLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_support_empty = df_joined.copy()\n",
    "\n",
    "# Drop of the useless column\n",
    "df_support_empty = df_support_empty.drop(columns=['ConferenceLocation', 'ConferenceNormalizedName', 'ConferenceTitle', 'OriginalTitle'])\n",
    "\n",
    "# Creation of the support column\n",
    "df_support_empty['Year_of_Citation'] = np.nan\n",
    "df_support_empty.rename(columns={'Year': 'Year_of_Publication'}, inplace=True)\n",
    "df_support_empty = df_support_empty.reindex(sorted(df_support_empty.columns), axis=1)\n",
    "\n",
    "df_support_empty.loc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Year Citation Columns to the Original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1950 # Probably there aren't citations before this date. We'll drop the empty columns later\n",
    "actual_year = date.today().year\n",
    "\n",
    "if not combine_with_partial_csv:\n",
    "    for i in range(start_year, actual_year + 1):\n",
    "        df_joined[str(i)] = 0\n",
    "else:\n",
    "    # We're going to use the partial joined dataframe\n",
    "    # The original dataframe was only needed for the creation of the support dataframe structure\n",
    "    df_joined = new_df_joined_partial.copy()\n",
    "    new_df_joined_partial = None\n",
    "\n",
    "df_joined.loc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Join of the COCI Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Files' Names\n",
    "coci_all_csvs = glob.glob(path_file_import + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "tot_csvs = coci_all_csvs.__len__()\n",
    "\n",
    "for current_csv_name in coci_all_csvs:\n",
    "\n",
    "    # Empty the support dataframe\n",
    "    df_support = df_support_empty.copy()\n",
    "\n",
    "    # Open the current CSV\n",
    "    print(f'Currently processing CSV {count} ({tot_csvs} total): {current_csv_name}')\n",
    "    count += 1\n",
    "    df_coci_current_csv = pd.read_csv(current_csv_name, low_memory=False)\n",
    "\n",
    "    # Drop of the useless columns: 'oci', 'citing', 'creation', 'journal_sc', 'author_sc'\n",
    "    df_coci_current_csv = df_coci_current_csv.drop(columns=['oci', 'citing', 'creation', 'journal_sc', 'author_sc'])\n",
    "\n",
    "    # Column rename\n",
    "    df_coci_current_csv = df_coci_current_csv.rename(columns={'cited': 'Doi'})\n",
    "\n",
    "    # Making sure that everything has the same format\n",
    "    df_coci_current_csv.Doi = df_coci_current_csv.Doi.str.lower()\n",
    "\n",
    "    # Join with the support dataframe\n",
    "    df_support = pd.merge(df_support, df_coci_current_csv, on=['Doi'], how='inner')\n",
    "\n",
    "    # Filtering the rows with a negative timespan\n",
    "    df_support.timespan = df_support[\"timespan\"].astype(str)\n",
    "    df_support = df_support[~df_support[\"timespan\"].str.contains('-')]\n",
    "\n",
    "    # Computing the citation's year\n",
    "    df_support.Year_of_Citation = df_support.timespan.str.split('Y').str[0].str.split('P').str[1]\n",
    "    df_support = df_support.dropna(subset=['Year_of_Citation']) # Drop of the broken records\n",
    "    df_support.Year_of_Citation = df_support.Year_of_Citation.astype(int) + df_support.Year_of_Publication.astype(int)\n",
    "\n",
    "    # Removing the broken records\n",
    "    df_support = df_support.loc[(df_support['Year_of_Citation'] <= actual_year)] # Keeping only year <= actual year\n",
    "    df_support = df_support.loc[(df_support['Year_of_Citation'] >= start_year)] # Keeping only year >= 1950\n",
    "\n",
    "    # Reshaping the dataframe and resetting its index\n",
    "    df_support_reshaped = pd.crosstab(df_support.Doi, df_support.Year_of_Citation)\n",
    "    df_support_reshaped = df_support_reshaped.reset_index()\n",
    "\n",
    "    # Fixing the column name type\n",
    "    for column in df_support_reshaped:\n",
    "        df_support_reshaped.rename(columns = {column: str(column)}, inplace=True)\n",
    "\n",
    "    # Join with the original dataframe\n",
    "    df_joined = pd.merge(df_joined, df_support_reshaped, on=['Doi'], how='left')\n",
    "\n",
    "    # Sum of the citation counts values\n",
    "    for column in df_joined:\n",
    "        if '_x' in str(column):\n",
    "            coci_column = str(column).split('_x')[0] + '_y'\n",
    "\n",
    "            # Replacing nan with zeros in the coci rows that didn't match\n",
    "            df_joined[coci_column] = df_joined[coci_column].fillna(0).astype(int)\n",
    "\n",
    "            # Column sum\n",
    "            df_joined[column] += df_joined[coci_column]\n",
    "            \n",
    "            # Column rename and drop\n",
    "            df_joined.rename(columns = {column: str(column).split('_x')[0]}, inplace=True)\n",
    "            df_joined = df_joined.drop(columns=[coci_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write of the Final CSV on Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the resulting dataframe on disk in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write of the resulting CSV on Disk\n",
    "df_joined.to_csv(path_file_export + 'out_citations_by_year_and_conferences.csv')\n",
    "print(f'Successfully Exported the Joined CSV to {path_file_export}out_citations_by_year_and_conferences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the Exported CSV to be sure that everything went fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of the Exported CSV\n",
    "df_joined_exported_csv = pd.read_csv(path_file_export + 'out_citations_by_year_and_conferences.csv', low_memory=False, index_col=[0])\n",
    "df_joined_exported_csv"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
