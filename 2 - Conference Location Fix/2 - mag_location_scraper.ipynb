{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location Web Scraping of Microsoft Academics Graph (MAG) Dataset\n",
    "\n",
    "Jupyter Notebook for the web scraping of the conferences locations of the Microsoft Academics Graph (MAG) dump.\n",
    "\n",
    "For this process, the following CSV file is needed: ```out_mag_citations_and_locations.csv```. \n",
    "The above file must be generated running the ```1 - mag_fix_locations_from_raw_dblp_dump.ipynb``` Notebook that is contained in the same folder as this Notebook.\n",
    "\n",
    "In particular, the following operations are going to be executed:\n",
    "* Opening of the CSV peprocessed dump\n",
    "* Obtaining the missing locations with queries to the DBLP website\n",
    "* Fix of the locations format\n",
    "\n",
    "Lastly, the entire preprocessed dump is going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import platform\n",
    "import multiprocessing as mp \n",
    "import concurrent       \n",
    "from location_scraper_multithread_utils import * \n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n",
    "Please set your working directory paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Import/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading Settings\n",
    "Settings needed for the multithreaded queries to gather the missing conferences locations from the DBLP website.\n",
    "\n",
    "Please specify the max number of workers below:\n",
    "\n",
    "**Important Note**: during our tests we found out that DBLP refuses incoming connections if requests are made too frequently. You can read more about the DBLP Servers Rate Limit [here](https://dblp.org/faq/1474706.html).\n",
    "\n",
    "We suggest to **set the number of workers to 1 if you have a large bandwidth** (over 100Mbps). Otherwise, you could try to set a higher value to make requests in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORKERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set a **sleep delay** (in seconds) between requests if that's not enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLEEP_DELAY = 0.3 # Seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special setting for the specific operating systems.\n",
    "\n",
    "**Note**: Due to the latest MacOS releases' security measures, we need to use the spawn method instead of fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook running on Darwin OS: \n",
      "Spawn method has been set\n"
     ]
    }
   ],
   "source": [
    "print(f\"Notebook running on {platform.system()} OS: \")\n",
    "\n",
    "if platform.system() == \"Darwin\" or platform.system() == \"Windows\": # MacOS and windows\n",
    "    mp_ctx = mp.get_context(\"spawn\")\n",
    "    print(\"Spawn method has been set\")\n",
    "    \n",
    "else: # other unix systems\n",
    "    mp_ctx = mp.get_context(\"fork\")\n",
    "    print(\"Fork method has been set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read of the CSV Preprocessed Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CitationCount</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceSeriesDisplayName</th>\n",
       "      <th>ConferenceSeriesNormalizedName</th>\n",
       "      <th>Doi</th>\n",
       "      <th>EstimatedCitation</th>\n",
       "      <th>OriginalTitle</th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>disc 2014</td>\n",
       "      <td>International Symposium on Distributed Computing</td>\n",
       "      <td>DISC</td>\n",
       "      <td>10.1007/978-3-662-45174-8_28</td>\n",
       "      <td>12</td>\n",
       "      <td>The Adaptive Priority Queue with Elimination a...</td>\n",
       "      <td>the adaptive priority queue with elimination a...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Wrocław, Poland</td>\n",
       "      <td>esa 2014</td>\n",
       "      <td>European Symposium on Algorithms</td>\n",
       "      <td>ESA</td>\n",
       "      <td>10.1007/978-3-662-44777-2_60</td>\n",
       "      <td>10</td>\n",
       "      <td>Document Retrieval on Repetitive Collections</td>\n",
       "      <td>document retrieval on repetitive collections</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Innsbruck, Austria</td>\n",
       "      <td>enter 2013</td>\n",
       "      <td>Information and Communication Technologies in ...</td>\n",
       "      <td>ENTER</td>\n",
       "      <td>10.1007/978-3-319-03973-2_13</td>\n",
       "      <td>20</td>\n",
       "      <td>SoCoMo Marketing for Travel and Tourism</td>\n",
       "      <td>socomo marketing for travel and tourism</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Provence, France</td>\n",
       "      <td>dexa 2002</td>\n",
       "      <td>Database and Expert Systems Applications</td>\n",
       "      <td>DEXA</td>\n",
       "      <td>10.1007/3-540-46146-9_77</td>\n",
       "      <td>0</td>\n",
       "      <td>Similarity Image Retrieval System Using Hierar...</td>\n",
       "      <td>similarity image retrieval system using hierar...</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>Zakopane, Poland</td>\n",
       "      <td>icaisc 2006</td>\n",
       "      <td>International Conference on Artificial Intelli...</td>\n",
       "      <td>ICAISC</td>\n",
       "      <td>10.1007/11785231_94</td>\n",
       "      <td>19</td>\n",
       "      <td>Leukemia prediction from gene expression data—...</td>\n",
       "      <td>leukemia prediction from gene expression data ...</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409807</th>\n",
       "      <td>4409807</td>\n",
       "      <td>0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>iecon 2020</td>\n",
       "      <td>Conference of the Industrial Electronics Society</td>\n",
       "      <td>IECON</td>\n",
       "      <td>10.1109/IECON43393.2020.9254316</td>\n",
       "      <td>0</td>\n",
       "      <td>Loss Reduction by Synchronous Rectification in...</td>\n",
       "      <td>loss reduction by synchronous rectification in...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409808</th>\n",
       "      <td>4409808</td>\n",
       "      <td>0</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>bmsb 2020</td>\n",
       "      <td>International Symposium on Broadband Multimedi...</td>\n",
       "      <td>BMSB</td>\n",
       "      <td>10.1109/BMSB49480.2020.9379806</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Over Cable Services – Improving the BICM ...</td>\n",
       "      <td>data over cable services improving the bicm ca...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409809</th>\n",
       "      <td>4409809</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acc 1988</td>\n",
       "      <td>American Control Conference</td>\n",
       "      <td>ACC</td>\n",
       "      <td>10.1109/ACC.1988.4172843</td>\n",
       "      <td>0</td>\n",
       "      <td>Model Reference Robust Adaptive Control withou...</td>\n",
       "      <td>model reference robust adaptive control withou...</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409810</th>\n",
       "      <td>4409810</td>\n",
       "      <td>0</td>\n",
       "      <td>Orlando, Florida, USA</td>\n",
       "      <td>icassp 2002</td>\n",
       "      <td>International Conference on Acoustics, Speech,...</td>\n",
       "      <td>ICASSP</td>\n",
       "      <td>10.1109/ICASSP.2002.1005676</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing data speech recognition in reverberant...</td>\n",
       "      <td>missing data speech recognition in reverberant...</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409811</th>\n",
       "      <td>4409811</td>\n",
       "      <td>0</td>\n",
       "      <td>Smart City, Xi'an, China</td>\n",
       "      <td>icit 2020</td>\n",
       "      <td>International Conference on Information Techno...</td>\n",
       "      <td>ICIT</td>\n",
       "      <td>10.1109/ITCA52113.2020.00077</td>\n",
       "      <td>0</td>\n",
       "      <td>Research on Text to Image Based on Generative ...</td>\n",
       "      <td>research on text to image based on generative ...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4409812 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  CitationCount        ConferenceLocation  \\\n",
       "0                 0             12                Austin, TX   \n",
       "1                 1             10           Wrocław, Poland   \n",
       "2                 2             20        Innsbruck, Austria   \n",
       "3                 3              0          Provence, France   \n",
       "4                 4             19          Zakopane, Poland   \n",
       "...             ...            ...                       ...   \n",
       "4409807     4409807              0                 Singapore   \n",
       "4409808     4409808              0             Paris, France   \n",
       "4409809     4409809              0                       NaN   \n",
       "4409810     4409810              0     Orlando, Florida, USA   \n",
       "4409811     4409811              0  Smart City, Xi'an, China   \n",
       "\n",
       "        ConferenceNormalizedName  \\\n",
       "0                      disc 2014   \n",
       "1                       esa 2014   \n",
       "2                     enter 2013   \n",
       "3                      dexa 2002   \n",
       "4                    icaisc 2006   \n",
       "...                          ...   \n",
       "4409807               iecon 2020   \n",
       "4409808                bmsb 2020   \n",
       "4409809                 acc 1988   \n",
       "4409810              icassp 2002   \n",
       "4409811                icit 2020   \n",
       "\n",
       "                               ConferenceSeriesDisplayName  \\\n",
       "0         International Symposium on Distributed Computing   \n",
       "1                         European Symposium on Algorithms   \n",
       "2        Information and Communication Technologies in ...   \n",
       "3                 Database and Expert Systems Applications   \n",
       "4        International Conference on Artificial Intelli...   \n",
       "...                                                    ...   \n",
       "4409807   Conference of the Industrial Electronics Society   \n",
       "4409808  International Symposium on Broadband Multimedi...   \n",
       "4409809                        American Control Conference   \n",
       "4409810  International Conference on Acoustics, Speech,...   \n",
       "4409811  International Conference on Information Techno...   \n",
       "\n",
       "        ConferenceSeriesNormalizedName                              Doi  \\\n",
       "0                                 DISC     10.1007/978-3-662-45174-8_28   \n",
       "1                                  ESA     10.1007/978-3-662-44777-2_60   \n",
       "2                                ENTER     10.1007/978-3-319-03973-2_13   \n",
       "3                                 DEXA         10.1007/3-540-46146-9_77   \n",
       "4                               ICAISC              10.1007/11785231_94   \n",
       "...                                ...                              ...   \n",
       "4409807                          IECON  10.1109/IECON43393.2020.9254316   \n",
       "4409808                           BMSB   10.1109/BMSB49480.2020.9379806   \n",
       "4409809                            ACC         10.1109/ACC.1988.4172843   \n",
       "4409810                         ICASSP      10.1109/ICASSP.2002.1005676   \n",
       "4409811                           ICIT     10.1109/ITCA52113.2020.00077   \n",
       "\n",
       "         EstimatedCitation                                      OriginalTitle  \\\n",
       "0                       12  The Adaptive Priority Queue with Elimination a...   \n",
       "1                       10       Document Retrieval on Repetitive Collections   \n",
       "2                       20            SoCoMo Marketing for Travel and Tourism   \n",
       "3                        0  Similarity Image Retrieval System Using Hierar...   \n",
       "4                       19  Leukemia prediction from gene expression data—...   \n",
       "...                    ...                                                ...   \n",
       "4409807                  0  Loss Reduction by Synchronous Rectification in...   \n",
       "4409808                  0  Data Over Cable Services – Improving the BICM ...   \n",
       "4409809                  0  Model Reference Robust Adaptive Control withou...   \n",
       "4409810                  0  Missing data speech recognition in reverberant...   \n",
       "4409811                  0  Research on Text to Image Based on Generative ...   \n",
       "\n",
       "                                                PaperTitle  Year  \n",
       "0        the adaptive priority queue with elimination a...  2014  \n",
       "1             document retrieval on repetitive collections  2014  \n",
       "2                  socomo marketing for travel and tourism  2013  \n",
       "3        similarity image retrieval system using hierar...  2002  \n",
       "4        leukemia prediction from gene expression data ...  2006  \n",
       "...                                                    ...   ...  \n",
       "4409807  loss reduction by synchronous rectification in...  2020  \n",
       "4409808  data over cable services improving the bicm ca...  2020  \n",
       "4409809  model reference robust adaptive control withou...  1988  \n",
       "4409810  missing data speech recognition in reverberant...  2002  \n",
       "4409811  research on text to image based on generative ...  2020  \n",
       "\n",
       "[4409812 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mag_preprocessed = pd.read_csv(path_file_export + 'out_mag_citations_and_locations.csv', low_memory=False)\n",
    "df_mag_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Missing Conferences Locations from the DBLP Website\n",
    "The missing conferences locations are going to be obtained from queries to the DBLP Website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mag_conferences = df_mag_preprocessed[[\"ConferenceNormalizedName\", \"ConferenceLocation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop of the papers that don't need their location to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConferenceNormalizedName</th>\n",
       "      <th>ConferenceLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acc 1990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>asilomar 1991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ire 1964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ecml 1994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>acc 1986</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409793</th>\n",
       "      <td>icieam 2017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409796</th>\n",
       "      <td>dueu 2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409803</th>\n",
       "      <td>ra 2004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409806</th>\n",
       "      <td>fnces 2012</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409809</th>\n",
       "      <td>acc 1988</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1694764 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ConferenceNormalizedName ConferenceLocation\n",
       "10                      acc 1990                NaN\n",
       "13                 asilomar 1991                NaN\n",
       "23                      ire 1964                NaN\n",
       "27                     ecml 1994                NaN\n",
       "39                      acc 1986                NaN\n",
       "...                          ...                ...\n",
       "4409793              icieam 2017                NaN\n",
       "4409796                dueu 2018                NaN\n",
       "4409803                  ra 2004                NaN\n",
       "4409806               fnces 2012                NaN\n",
       "4409809                 acc 1988                NaN\n",
       "\n",
       "[1694764 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mag_conferences = df_mag_conferences[df_mag_conferences[\"ConferenceLocation\"].isna()]\n",
    "df_mag_conferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop of the duplicated conferences. We only need unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we only need to search for the location of 14911 unique conferences\n"
     ]
    }
   ],
   "source": [
    "df_mag_conferences = df_mag_conferences.drop_duplicates(subset=\"ConferenceNormalizedName\")\n",
    "\n",
    "print(f\"Now we only need to search for the location of {df_mag_conferences.__len__()} unique conferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define of the Web Scraping Function\n",
    "We'll do a web scraping in two different URL formats, hence the need of two web scraping phases (with two different functions that are going to be passed as parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dblp_location_scraper(conferences_dataframe, mt_downloader_operation_function, dblp_url = \"https://dblp.org/db/conf/\"):\n",
    "    dict_conf_locations = {}      \n",
    "    download_list = list(conferences_dataframe.ConferenceNormalizedName.values)\n",
    "\n",
    "    executor = concurrent.futures.ProcessPoolExecutor(max_workers=int(MAX_WORKERS), mp_context=mp_ctx)\n",
    "    futures = [executor.submit(mt_downloader_operation_function, conf_name, dblp_url, SLEEP_DELAY) for conf_name in download_list]\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            k, v = future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"{futures[future]} throws {e}\")\n",
    "        else:\n",
    "            dict_conf_locations[k] = v\n",
    "            pass\n",
    "\n",
    "    # Converting the resulting dictionary to a dataframe\n",
    "    df_conf_locations = pd.DataFrame(dict_conf_locations.items(), columns=['ConferenceNormalizedName', 'ConferenceLocation'])\n",
    "\n",
    "    return df_conf_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries to https://dblp.org/db/conf/CONF_NAME/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel execution of the queries to the DBLP website.\n",
    "\n",
    "**Note**: this operation should take less than six hours, depending on your Internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dblp.org/db/conf/acc/index.html - Year 1990: None\n",
      "https://dblp.org/db/conf/ecml/index.html - Year 1994: <h2 id=\"1994\">7th ECML 1994: Catania, Italy</h2>\n",
      "https://dblp.org/db/conf/acc/index.html - Year 1986: None\n",
      "https://dblp.org/db/conf/acc/index.html - Year 1994: None\n",
      "https://dblp.org/db/conf/embc/index.html - Year 2003: None\n",
      "https://dblp.org/db/conf/wcc/index.html - Year 2006: None\n",
      "https://dblp.org/db/conf/iscas/index.html - Year 1998: <h2 id=\"1998\">ISCAS 1998: Monterey, CA, USA</h2>\n",
      "https://dblp.org/db/conf/emnets/index.html - Year 2005: <h2 id=\"2005\">EmNets 2005: Sydney, Australia</h2>\n",
      "https://dblp.org/db/conf/embc/index.html - Year 2000: None\n",
      "https://dblp.org/db/conf/ecoop/index.html - Year 1997: <h2 id=\"1997\">11th ECOOP 1997: Jyväskylä, Finland</h2>\n",
      "https://dblp.org/db/conf/icee/index.html - Year 2012: None\n",
      "https://dblp.org/db/conf/ecoc/index.html - Year 2007: None\n",
      "https://dblp.org/db/conf/wdag/index.html - Year 1997: <h2 id=\"1997\">11th WDAG 1997: Saarbrücken, Germany</h2>\n",
      "https://dblp.org/db/conf/websci/index.html - Year 2006: None\n",
      "https://dblp.org/db/conf/websci/index.html - Year 1996: None\n",
      "https://dblp.org/db/conf/ofc/index.html - Year 2005: None\n",
      "https://dblp.org/db/conf/cvmp/index.html - Year 2009: None\n",
      "https://dblp.org/db/conf/cinc/index.html - Year 2005: None\n",
      "https://dblp.org/db/conf/ncc/index.html - Year 1963: None\n",
      "https://dblp.org/db/conf/ims/index.html - Year 1983: None\n",
      "https://dblp.org/db/conf/allerton/index.html - Year 2009: None\n",
      "https://dblp.org/db/conf/ipc/index.html - Year 2012: None\n",
      "https://dblp.org/db/conf/cdc/index.html - Year 1990: None\n",
      "https://dblp.org/db/conf/cc/index.html - Year 1987: None\n",
      "https://dblp.org/db/conf/ncc/index.html - Year 1969: None\n",
      "https://dblp.org/db/conf/icbbe/index.html - Year 2008: None\n",
      "https://dblp.org/db/conf/vcip/index.html - Year 1997: None\n",
      "https://dblp.org/db/conf/iscas/index.html - Year 1997: None\n",
      "https://dblp.org/db/conf/icon/index.html - Year 1995: None\n",
      "https://dblp.org/db/conf/cdc/index.html - Year 1994: None\n",
      "https://dblp.org/db/conf/hicss/index.html - Year 1993: None\n",
      "https://dblp.org/db/conf/cc/index.html - Year 1993: None\n",
      "https://dblp.org/db/conf/wfcs/index.html - Year 1995: None\n",
      "https://dblp.org/db/conf/igarss/index.html - Year 1996: None\n",
      "https://dblp.org/db/conf/ats/index.html - Year 1994: None\n",
      "https://dblp.org/db/conf/acc/index.html - Year 2005: None\n",
      "https://dblp.org/db/conf/cdc/index.html - Year 1985: None\n",
      "https://dblp.org/db/conf/pac/index.html - Year 1989: None\n",
      "https://dblp.org/db/conf/cdc/index.html - Year 1986: None\n",
      "https://dblp.org/db/conf/iecon/index.html - Year 1993: None\n",
      "https://dblp.org/db/conf/pac/index.html - Year 1997: None\n",
      "https://dblp.org/db/conf/ims/index.html - Year 1973: None\n",
      "https://dblp.org/db/conf/prime/index.html - Year 2007: None\n",
      "https://dblp.org/db/conf/norchip/index.html - Year 2008: None\n",
      "https://dblp.org/db/conf/sensors/index.html - Year 2002: None\n",
      "https://dblp.org/db/conf/isit/index.html - Year 2001: None\n",
      "https://dblp.org/db/conf/ichit/index.html - Year 2008: None\n",
      "https://dblp.org/db/conf/ijcnn/index.html - Year 2004: <h2 id=\"2004\">IJCNN / <a href=\"https://dblp.org/db/conf/icann/index.html\">ICANN</a> 2004: Budapest, Hungary</h2>\n",
      "https://dblp.org/db/conf/issnip/index.html - Year 2008: None\n",
      "https://dblp.org/db/conf/smc/index.html - Year 1993: None\n"
     ]
    }
   ],
   "source": [
    "df_conf_locations_v1 = dblp_location_scraper(df_mag_conferences, mt_get_mag_conf_location_from_dblp_operation_v1, \"https://dblp.org/db/conf/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many conference locations have been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_locations_v1 = df_conf_locations_v1.dropna(subset = ['ConferenceLocation'])\n",
    "\n",
    "print(f\"Fixed {len(df_conf_locations_v1.index)} over {len(df_mag_conferences.index)} unique conferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write of the fixed locations on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_locations_v1.to_csv(path_file_export + 'out_mag_locations_fixed_v1.csv')\n",
    "print(f'Successfully Exported the Preprocessed CSV to {path_file_export}out_mag_locations_fixed_v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries to https://dblp.org/db/conf/CONF_NAME/CONF_NAMEYEAR.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel execution of the queries to the DBLP website.\n",
    "\n",
    "**Note**: this operation should take less than six hours, depending on your Internet speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we have to filter the conferences that have already been obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = df_mag_conferences[\"ConferenceNormalizedName\"].isin(df_conf_locations_v1[\"ConferenceNormalizedName\"])\n",
    "df_mag_conferences.drop(df_mag_conferences[rows_to_drop].index, inplace=True)\n",
    "\n",
    "print(f\"Now we only need to search for the location of {df_mag_conferences.__len__()} unique conferences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_locations_v2 = dblp_location_scraper(df_mag_conferences, mt_get_mag_conf_location_from_dblp_operation_v2, \"https://dblp.org/db/conf/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many conference locations have been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_locations_v2 = df_conf_locations_v2.dropna(subset = ['ConferenceLocation'])\n",
    "\n",
    "print(f\"Fixed {len(df_conf_locations_v2.index)} over {len(df_mag_conferences.index)} unique conferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write of the fixed locations on disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf_locations_v2.to_csv(path_file_export + 'out_mag_locations_fixed_v2.csv')\n",
    "print(f'Successfully Exported the Preprocessed CSV to {path_file_export}out_mag_locations_fixed_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join of the New Location Data with the Original Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the first location dataframe\n",
    "df_mag_preprocessed = pd.merge(df_mag_preprocessed, df_conf_locations_v1, on=['ConferenceNormalizedName'], how='left')\n",
    "\n",
    "# Combine the two columns\n",
    "df_mag_preprocessed['ConferenceLocation_x'] = df_mag_preprocessed['ConferenceLocation_x'].fillna(df_mag_preprocessed['ConferenceLocation_y'])\n",
    "df_mag_preprocessed.rename(columns = {'ConferenceLocation_x':'ConferenceLocation'}, inplace=True)\n",
    "df_mag_preprocessed = df_mag_preprocessed.drop(columns=['ConferenceLocation_y'])\n",
    "\n",
    "\n",
    "# Merge with the second location dataframe\n",
    "df_mag_preprocessed = pd.merge(df_mag_preprocessed, df_conf_locations_v2, on=['ConferenceNormalizedName'], how='left')\n",
    "\n",
    "# Combine the two columns\n",
    "df_mag_preprocessed['ConferenceLocation_x'] = df_mag_preprocessed['ConferenceLocation_x'].fillna(df_mag_preprocessed['ConferenceLocation_y'])\n",
    "df_mag_preprocessed.rename(columns = {'ConferenceLocation_x':'ConferenceLocation'}, inplace=True)\n",
    "df_mag_preprocessed = df_mag_preprocessed.drop(columns=['ConferenceLocation_y'])\n",
    "\n",
    "\n",
    "df_mag_preprocessed.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of how many paper's conference locations are still missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missing = len(df_mag_preprocessed.index) - len(df_mag_preprocessed.dropna(subset = ['ConferenceLocation']).index)\n",
    "print(f\"{n_missing} missing paper's conference locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write of the Final CSV on Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write of the resulting CSV on Disk\n",
    "df_mag_preprocessed.to_csv(path_file_export + 'out_mag_citations_and_locations_final.csv')\n",
    "print(f'Successfully Exported the Preprocessed CSV to {path_file_export}out_mag_citations_and_locations_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check of the Exported CSV to be sure that everything went fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of the Exported CSV\n",
    "df_mag_exported_csv = pd.read_csv(path_file_export + 'out_mag_citations_and_locations_final.csv', low_memory=False, index_col=[0])\n",
    "df_mag_exported_csv.drop(df_mag_exported_csv.filter(regex=\"Unname\"), axis=1, inplace=True)\n",
    "df_mag_exported_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order by citations count descending to see the articles with the most citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by citations count descending to see the articles with the most citations\n",
    "df_mag_exported_csv = df_mag_exported_csv.sort_values(by='CitationCount', ascending=False)\n",
    "df_mag_exported_csv.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
