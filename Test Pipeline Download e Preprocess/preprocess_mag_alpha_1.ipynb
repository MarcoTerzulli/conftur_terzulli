{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************************\n",
    "# Preprocess Microsoft Academics Graph (MAG) Dataset\n",
    "# ***************************************************************\n",
    "\n",
    "# Jupyter Notebook for the preprocessing of the Microsoft Academics Graph (MAG) dump\n",
    "#\n",
    "# TODO **********\n",
    "# In particular, the following operations are going to be executed:\n",
    "# - (sequential) opening of the dump's CSVs\n",
    "# - Drop of the useless columns (only 'cited' is going to remain)\n",
    "# - Gruop by on the 'cited' column and count\n",
    "# - Union with the dataframe of the CSVs previously elaborated\n",
    "#\n",
    "# Lastly, the entire preprocessed dump is going to be saved on disk in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************* PATHS ********************+\n",
    "\n",
    "# Dumps Directory Path\n",
    "path_file_import = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/MAG/'\n",
    "\n",
    "# CSV Exports Directory Path\n",
    "path_file_export = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/'\n",
    "\n",
    "# Combine New Data with a \"Partial\" CSV\n",
    "#\n",
    "# This can be really useful in case of limited disk space, allowing us to partially process \n",
    "# the dump (using a subset of the CSVs) and free some space on disk by deleting the CSVs \n",
    "# that have been already processed.\n",
    "#\n",
    "# Note: the delete operations need to be made manually\n",
    "# Note: the partial CSV needs to be in the same format of the one generated with this script\n",
    "combine_with_partial_csv = False\n",
    "partial_csv_path = r'/Users/marcoterzulli/File/Scuola Local/Magistrale/Materiale Corsi Attuali/Tirocinio/Cartella di Lavoro/Archivi Dump di Lavoro/Export/out_coci_partial.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Files' Names\n",
    "coci_all_csvs = glob.glob(path_file_import + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coci_processed = pd.DataFrame(columns=['article', 'citations_count'])\n",
    "\n",
    "# Combine new data with a partial CSV\n",
    "if combine_with_partial_csv:\n",
    "    df_coci_processed = pd.read_csv(partial_csv_path, low_memory=False)\n",
    "    print(f'Successfully Imported the Partial CSV')\n",
    "    \n",
    "# Read, process and concat all CSVs\n",
    "count = 0\n",
    "for current_csv_name in coci_all_csvs:\n",
    "\n",
    "    # Open the current CSV\n",
    "    print(f'Currently processing CSV {count}: {current_csv_name}')\n",
    "    count += 1\n",
    "    df_coci_current_csv = pd.read_csv(current_csv_name, low_memory=False)\n",
    "\n",
    "    # Drop of the useless columns: 'oci', 'citing', 'creation', 'timespan', 'journal_sc', 'author_sc'\n",
    "    df_coci_current_csv.drop(columns=['oci', 'citing', 'creation', 'timespan', 'journal_sc', 'author_sc'])\n",
    "\n",
    "    # Group by cited article and count\n",
    "    sf_coci_current_grouped = df_coci_current_csv.groupby(['cited'])['cited'].count()\n",
    "\n",
    "    # Since the returned object is a Pandas Series type, we need to convert it to a Pandas dataframe\n",
    "    df_coci_current_csv = pd.DataFrame({'article':sf_coci_current_grouped.index, 'citations_count':sf_coci_current_grouped.values})\n",
    "\n",
    "    ### Concat with the data previously elaborated\n",
    "    df_coci_processed = pd.concat([df_coci_processed, df_coci_current_csv])\n",
    "\n",
    "    # Now we need to do a new group by and sum the citations_count to reduce the data\n",
    "    sf_coci_processed_grouped = df_coci_processed.groupby(['article'])['citations_count'].sum()\n",
    "    df_coci_processed = pd.DataFrame({'article':sf_coci_processed_grouped.index, 'citations_count':sf_coci_processed_grouped.values})\n",
    "\n",
    "# Export of the final dataframe\n",
    "df_coci_processed.to_csv(path_file_export + 'out_coci_citations_count.csv')\n",
    "print(f'Successfully Exported the Preprocessed CSV to {path_file_export}out_coci_citations_count.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of the Exported CSV\n",
    "df_coci_exported_csv = pd.read_csv(path_file_export + 'out_coci_citations_count.csv', low_memory=False)\n",
    "df_coci_exported_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by citations count descending to see the articles with the most citations\n",
    "df_coci_exported_csv = df_coci_exported_csv.sort_values(by='citations_count', ascending=False)\n",
    "df_coci_exported_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the total count of the citations contained in the extracted CSV\n",
    "df_coci_exported_csv['citations_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
